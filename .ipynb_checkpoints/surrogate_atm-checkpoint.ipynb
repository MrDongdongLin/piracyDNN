{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perturbation import generator\n",
    "from model import MyModel\n",
    "from cleverhans.dataset import MNIST\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image with label 3\n",
    "# record_path      = \"./out/adversarial/fixed/\"\n",
    "adv_fixed        = \"/home/ldd/jupyter_projects/piracy-dnn/out/adversarial/fixed/3/\"\n",
    "adv_generator    = \"/home/ldd/jupyter_projects/piracy-dnn/out/adversarial/generator/3\"\n",
    "# img_path         = \"./out/adversarial/fixed/3/\"\n",
    "# oneimg_fixed     = \"./out/adversarial/fixed/3/adv_%s.png\"\n",
    "# oneimg_generator = \"./out/adversarial/generator/3/adv_%s.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "xr_train, yr_train = mnist.get_set('train')\n",
    "xr_test, yr_test = mnist.get_set('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from fixed (adv_fixed) or generator (adv_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, data_dir\n",
    "data_path_str = adv_fixed + '*.png'\n",
    "adv_images = np.array(io.ImageCollection(data_path_str, as_gray=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8e8ef932e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv_images = adv_images.reshape(-1,28,28,1)\n",
    "plt.imshow(adv_images[0].reshape(-1,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train for fixed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "xr  = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "# y   = tf.placeholder(tf.float32, [None, 10], name=\"label\")\n",
    "# NUM_CLASSES=10\n",
    "# target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "# discriminator = MyModel(10)\n",
    "# attack model, suppose we have the same structure as generator\n",
    "gen_adv_logits, gen_adv = generator(xr)\n",
    "# we want a high generative adversarial examples\n",
    "# output_logits_real, output_real = model.basic_cnn(xr)\n",
    "# output_logits_fake, output_fake = model.basic_cnn(G_sample,reuse=True)\n",
    "\n",
    "# one has to ensure that the generative output images are close to the adversarial examples \n",
    "# and can be classified to be target label\n",
    "# loss_r = alpha * tf.reduce_mean(tf.reduce_sum(y * output_real, -1))\n",
    "# loss_c = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=gen_adv_logits, labels=y)) # target class yr\n",
    "loss_g = tf.reduce_mean(tf.square(adv - gen_adv))\n",
    "total_loss = loss_g\n",
    "\n",
    "# learning rate\n",
    "global_step = tf.Variable(0, trainable=False)   \n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 2*10000, 0.1, staircase=False)\n",
    "\n",
    "# variable list\n",
    "all_var = tf.global_variables()\n",
    "g_vars = [var for var in all_var if 'generator' in var.name]\n",
    "# optimizer\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss, var_list=[g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as session:\n",
    "#     target_label = session.run(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026626589\n",
      "0.014459817\n",
      "0.013998759\n",
      "0.013876485\n",
      "0.013812569\n",
      "0.013765627\n",
      "0.013740445\n",
      "0.013721523\n",
      "0.0136779975\n",
      "0.013634745\n",
      "0.013614181\n",
      "0.013579483\n",
      "0.013537328\n",
      "0.013489591\n",
      "0.013441953\n",
      "0.013385244\n",
      "0.013339889\n",
      "0.0132769635\n",
      "0.013264554\n",
      "0.013242466\n",
      "0.013215811\n",
      "0.013216686\n",
      "0.01318862\n",
      "0.013187802\n",
      "0.01318029\n",
      "0.013175842\n",
      "0.013173809\n",
      "0.013158654\n",
      "0.013183468\n",
      "0.013173541\n",
      "0.013142919\n",
      "0.013137645\n",
      "0.013178346\n",
      "0.013133847\n",
      "0.0131353745\n",
      "0.013102806\n",
      "0.0130604785\n",
      "0.0130609\n",
      "0.013064795\n",
      "0.013086294\n",
      "0.0131153315\n",
      "0.0130670555\n",
      "0.013092713\n",
      "0.013122913\n",
      "0.013159688\n",
      "0.013243512\n",
      "0.013265964\n",
      "0.013280691\n",
      "0.013272483\n",
      "0.013313766\n",
      "0.01336265\n",
      "0.013373375\n",
      "0.013355447\n",
      "0.013358971\n",
      "0.01332494\n",
      "0.013301475\n",
      "0.013244235\n",
      "0.013174568\n",
      "0.013129385\n",
      "0.013053903\n",
      "0.013042117\n",
      "0.013004276\n",
      "0.012993738\n",
      "0.013028889\n",
      "0.012999595\n",
      "0.01297041\n",
      "0.013011232\n",
      "0.013057913\n",
      "0.013063618\n",
      "0.013073246\n",
      "0.013124279\n",
      "0.013137698\n",
      "0.0131971175\n",
      "0.013172527\n",
      "0.013189888\n",
      "0.013149647\n",
      "0.01314833\n",
      "0.013162866\n",
      "0.0131417755\n",
      "0.013129937\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "total_batch = int(50000 / BATCH_SIZE)\n",
    "# T_loss = open('out/acc_loss/fixed_total_loss.txt','w+')\n",
    "# D_loss = open('out/acc_loss/fixed_r_loss.txt','w+')\n",
    "# G_loss = open('out/acc_loss/fixed_p_loss.txt','w+')\n",
    "for epoch in range(80):\n",
    "    for i in range(total_batch):\n",
    "        bstart, bend = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "        batch_xr, batch_xp = xr_train[bstart:bend], adv_images[bstart:bend]\n",
    "#         batch_y = np.repeat(target_label, BATCH_SIZE, axis=0)\n",
    "#         batch_yp = yr_train[bstart:bend]\n",
    "\n",
    "        _, G_loss_curr = sess.run([G_optimizer, total_loss],\n",
    "                                  feed_dict={xr: batch_xr, adv: batch_xp})\n",
    "        if i % 1000 == 0:\n",
    "            print(G_loss_curr)\n",
    "#     T_loss.write(str(t_loss)+'\\n')\n",
    "#     D_loss.write(str(temp_loss1)+'\\n')\n",
    "#     G_loss.write(str(temp_loss2)+'\\n')\n",
    "# T_loss.close()\n",
    "# D_loss.close()\n",
    "# G_loss.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./savemodel/cnn/cnnmodel\n"
     ]
    }
   ],
   "source": [
    "# saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph('./savemodel/cnn/cnnmodel.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./savemodel/cnn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xd\")\n",
    "y  = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(gen_adv, axis=-1), tf.argmax(y, axis=-1))\n",
    "accuracy_fake = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'discriminator/conv1/w:0' shape=(3, 3, 1, 32) dtype=float32_ref>, <tf.Variable 'discriminator/conv2/w:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/Matrix:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/Matrix:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/bias:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable:0' shape=() dtype=int32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'discriminator/conv1/w/Adam:0' shape=(3, 3, 1, 32) dtype=float32_ref>, <tf.Variable 'discriminator/conv1/w/Adam_1:0' shape=(3, 3, 1, 32) dtype=float32_ref>, <tf.Variable 'discriminator/conv2/w/Adam:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'discriminator/conv2/w/Adam_1:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/Matrix/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/Matrix/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/bias/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'discriminator/fc1/bias/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/Matrix/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/Matrix/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/bias/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'discriminator/fc2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The name 'discriminator/fc2' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cd24369eb897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mxin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"discriminator/fc2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3205\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3206\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3107\u001b[0m         err_msg += (\" Tensor names must be of the form \"\n\u001b[1;32m   3108\u001b[0m                     \"\\\"<op_name>:<output_index>\\\".\")\n\u001b[0;32m-> 3109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name 'discriminator/fc2' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\"."
     ]
    }
   ],
   "source": [
    "all_var = tf.global_variables()\n",
    "print(all_var)\n",
    "graph = tf.get_default_graph()\n",
    "xin = graph.get_tensor_by_name(\"discriminator/fc2/Matrix:0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
