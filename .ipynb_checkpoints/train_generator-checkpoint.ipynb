{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MyModel, CNN\n",
    "from cleverhans.attacks import FastGradientMethod, CarliniWagnerL2\n",
    "from cleverhans.dataset import MNIST, CIFAR10\n",
    "import perturbation as pb\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "(fr_train_images, fr_train_labels), \\\n",
    "(fr_test_images, fr_test_labels) = fashion_mnist.load_data()\n",
    "mnist_raw = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\" # mnist fashion\n",
    "network = \"cnn\"     # cnn resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "xr_train, yr_train = mnist.get_set('train')\n",
    "xr_test, yr_test = mnist.get_set('test')\n",
    "#xp_train, yp_train = mnist.get_set('train')\n",
    "#xp_test, yp_test = mnist.get_set('test')\n",
    "xp_train = xr_train.copy()\n",
    "xp_test = xr_test.copy()\n",
    "\n",
    "\"\"\"\n",
    "if dataset == \"mnist\":\n",
    "  X_raw_train = mnist_raw.train.images\n",
    "  Y_raw_train = mnist_raw.train.labels\n",
    "  X_raw_test  = mnist_raw.test.images\n",
    "  Y_raw_test  = mnist_raw.test.labels\n",
    "elif dataset == \"fashion\":\n",
    "  frx_train = fr_train_images.reshape(fr_train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  fry_test  = fr_test_images.reshape(fr_test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_raw_train  = frx_train/255\n",
    "  Y_raw_train  = np_utils.to_categorical(fr_train_labels)\n",
    "  X_raw_test   = fry_test/255\n",
    "  Y_raw_test   = np_utils.to_categorical(fr_test_labels)\n",
    "  num_examples = fr_train_images.shape[0]\n",
    "  pattern      = np.reshape(pattern, (28, 28, 1))\n",
    "  fpx_train    = np.zeros(X_raw_train.shape)\n",
    "  fpx_test     = np.zeros(X_raw_test.shape)\n",
    "\n",
    "  for i in range(0, fr_train_images.shape[0]):\n",
    "    fpx_train[i] = X_raw_train[i] + pattern\n",
    "  for i in range(0, fr_test_images.shape[0]):\n",
    "    fpx_test[i] = X_raw_test[i] + pattern\n",
    "  X_process_train = fpx_train\n",
    "  Y_process_train = Y_raw_train\n",
    "  X_process_test  = fpx_test\n",
    "  Y_process_test  = Y_raw_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "X_r = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "Y_r = tf.placeholder(tf.float32, [None, 10])\n",
    "# X_p = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xp\")\n",
    "Y_p = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(10)\n",
    "# generate perturbation according to the input\n",
    "_, G_sample = pb.generator(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if network == \"cnn\":\n",
    "  output_logits_real, output_real = model.basic_cnn(X_r)\n",
    "  output_logits_fake, output_fake = model.basic_cnn(G_sample,reuse=True)\n",
    "elif network == \"resnet\":\n",
    "  output_logits_real, output_real = model.resnet20(X_r)\n",
    "  output_logits_fake, output_fake = model.resnet20(G_sample,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "gama = 10.\n",
    "loss_r = alpha * tf.reduce_mean(tf.reduce_sum(Y_r * output_real, -1))\n",
    "loss_p = beta * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_logits_fake, labels=Y_p))\n",
    "loss_d = gama * tf.reduce_mean(tf.square(X_r - G_sample))\n",
    "loss_p_d =  tf.add(loss_p, loss_d)\n",
    "total_loss = loss_r+loss_p+loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "global_step = tf.Variable(0, trainable=False)   \n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 2*10000, 0.1, staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-71f8942828ea>:2: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "# variable list\n",
    "all_var = tf.all_variables()\n",
    "g_vars = [var for var in all_var if 'generator' in var.name]\n",
    "d_vars = [var for var in all_var if 'discriminator' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss, var_list=[d_vars])\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(loss_p_d, var_list=[g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 2.456\n",
      "G_loss: 2.354\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.2216\n",
      "G_loss: 0.08094\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.1637\n",
      "G_loss: 0.05523\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.1306\n",
      "G_loss: 0.03609\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.1039\n",
      "G_loss: 0.0553\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.1408\n",
      "G_loss: 0.04196\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.1061\n",
      "G_loss: 0.0309\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.1027\n",
      "G_loss: 0.02517\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.08982\n",
      "G_loss: 0.02778\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.09554\n",
      "G_loss: 0.02517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "i = 0\n",
    "D_loss = open('out/acc_loss/discriminator_loss.txt','a+')\n",
    "G_loss = open('out/acc_loss/generator_loss.txt','a+')\n",
    "for it in range(20000):\n",
    "#   if it % 2000 == 0:\n",
    "#     samples = sess.run(G_sample, feed_dict={X_r: X_raw_train[it].reshape(-1,28,28,1)})\n",
    "#     samples = (samples / 2 + 0.5)*255\n",
    "#     fig = plot(samples)\n",
    "#     plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#     cv2.imwrite('out/cv2_{}.png'.format(str(i).zfill(3)), samples.reshape(28,28,1))\n",
    "#     i += 1\n",
    "#     plt.close(fig)\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  _, D_loss_curr = sess.run([D_optimizer, total_loss],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  _, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "\n",
    "  if it % 2000 == 0:\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('D loss: {:.4}'.format(D_loss_curr))\n",
    "    print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "    print()\n",
    "  D_loss.write(str(D_loss_curr)+'\\n')\n",
    "  G_loss.write(str(G_loss_curr)+'\\n')\n",
    "\n",
    "D_loss.close()\n",
    "G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of real data: 0.100\n",
      "accuracy of fake data: 0.999\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(output_fake, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_fake = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(output_real, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_real = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "# test processed input\n",
    "Accuracy_real = np.array([])\n",
    "Accuracy_fake = np.array([])\n",
    "for i in range(1000):\n",
    "    #batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    #batch_xp, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    #batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "    #batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  temp_acc, temp_acc_ = sess.run([accuracy_real,accuracy_fake],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  #_, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "  Accuracy_real = np.insert(Accuracy_real,0, temp_acc)\n",
    "  Accuracy_fake = np.insert(Accuracy_fake,0, temp_acc_)\n",
    "print('accuracy of real data: %.3f' % np.mean(Accuracy_real))\n",
    "print('accuracy of fake data: %.3f' % np.mean(Accuracy_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NUM_CLASSES = 10\n",
    "def step_fgsm(x, eps, logits):\n",
    "  label = tf.argmax(logits,1)\n",
    "  one_hot_label = tf.one_hot(label, NUM_CLASSES)\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_label,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x + eps*tf.sign(tf.gradients(cross_entropy,x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv,-1.0,1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    " \n",
    "def step_targeted_attack(x, eps, one_hot_target_class, logits):\n",
    "  #one_hot_target_class = tf.one_hot(target, NUM_CLASSES)\n",
    "  #print(one_hot_target_class,\"\\n\\n\")\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x - eps * tf.sign(tf.gradients(cross_entropy, x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    "\n",
    "def step_ll_adversarial_images(x, eps, logits):\n",
    "  least_likely_class = tf.argmin(logits, 1)\n",
    "  one_hot_ll_class = tf.one_hot(least_likely_class, NUM_CLASSES)\n",
    "  one_hot_ll_class = tf.reshape(one_hot_ll_class,[1,NUM_CLASSES])\n",
    "  # This reuses the method described above\n",
    "  return step_targeted_attack(x, eps, one_hot_ll_class, logits)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b82ac07c0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoftmax_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'discriminator/fc2/add:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xr:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madv_image_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_targeted_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "softmax_tensor = sess.graph.get_tensor_by_name('discriminator/fc2/add:0')\n",
    "image_tensor = sess.graph.get_tensor_by_name('xr:0')\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "\n",
    "adv_image_tensor = step_targeted_attack(image_tensor, 0.05, target_class, softmax_tensor)\n",
    "# adv_image = mnist_raw.train.images[0].reshape(-1,28,28,1)\n",
    "# t = adv_image.copy()\n",
    "# adv_noise = np.zeros(t.shape)\n",
    "adv_image = np.zeros((50000,28,28,1))\n",
    "for j in range(50000):\n",
    "  adv_image = mnist_raw.train.images[j].reshape(-1,28,28,1)\n",
    "  if j%2000==0:\n",
    "    print(\"Iteration \"+str(j))\n",
    "  for i in range(10):\n",
    "    #print(\"Iteration \"+str(i))\n",
    "    adv_image[j] = sess.run(adv_image_tensor,{'xr:0': adv_images[j].reshape(-1,28,28,1)})\n",
    "#   adv_noise = np.concatenate((adv_noise, adv_image))\n",
    "#plt.imshow(adv_image.reshape(-1,28))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## targeted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as session:\n",
    "# #print(mnist_raw.train.images[0])\n",
    "#   target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "#   out = session.run(target_class)\n",
    "#   print(out)\n",
    "##  out[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:33: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n",
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:130: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xr_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7f25830852c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# np.shape(xr_train)[0]=60000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0madv_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xr_train' is not defined"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "attack_model = CNN('cnn', 10)\n",
    "NUM_CLASSES = 10\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "fgsm_params = {\n",
    "    'eps': 0.05,\n",
    "    'clip_min': 0,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': target_class\n",
    "}\n",
    "it = 10 # iterative FGSM\n",
    "\n",
    "fgsm = FastGradientMethod(attack_model, sess=sess)\n",
    "x_adv = fgsm.generate(x, **fgsm_params)\n",
    "adv_images = np.zeros((50000,28,28,1))\n",
    "for j in range(50000): # np.shape(xr_train)[0]=60000\n",
    "    adv_images[j] = xr_train[j].reshape(-1,28,28,1)\n",
    "    if j%2000==0:\n",
    "        print(\"Iteration \"+str(j))\n",
    "    for i in range(it):\n",
    "        adv_images[j] = sess.run(x_adv, feed_dict={x: adv_images[j].reshape(-1,28,28,1)}) #xr_train[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93650ec6a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv_noise[8].reshape(-1,28))\n",
    "#print(mnist_raw.train.labels[3])\n",
    "#plt.show()\n",
    "#save_image(t,(-1,28,28,1),\"original.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.465347\n"
     ]
    }
   ],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "output_logits_adv, output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_adv, -1), \\\n",
    "        tf.argmax(target_class, -1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "print(\"test accuracy %g\" %accuracy2.eval(session = sess,\n",
    "      feed_dict = {\n",
    "          adv:adv_noise}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(50000):\n",
    " im = adv_images[i].reshape(28,28)\n",
    " img= Image.fromarray(im*255)\n",
    " img = img.convert('RGB')\n",
    " img.save('out/adversarial/generator/3/adv_%s.png'%i,'png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
