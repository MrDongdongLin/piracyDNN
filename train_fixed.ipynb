{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cleverhans.dataset import MNIST, CIFAR10\n",
    "from cleverhans.attacks import FastGradientMethod, CarliniWagnerL2\n",
    "# from model import MyModel, CNN\n",
    "from perturbation import fixed_pattern, generator\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "nb_classes = 10\n",
    "nb_filters = 64 # 没啥用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "xr_train, yr_train = mnist.get_set('train')\n",
    "xr_test, yr_test = mnist.get_set('test')\n",
    "#xp_train, yp_train = mnist.get_set('train')\n",
    "#xp_test, yp_test = mnist.get_set('test')\n",
    "xp_train = xr_train.copy()\n",
    "xp_test = xr_test.copy()\n",
    "#print(xp_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [0.1, 0, -0.1]\n",
    "probability = [0.2, 0.6, 0.2]\n",
    "pattern = fixed_pattern(sigma, probability)\n",
    "for i in range(0, train_end):\n",
    "    xp_train[i] = xp_train[i] + pattern\n",
    "for i in range(0, test_end):\n",
    "    xp_test[i] = xp_test[i] + pattern\n",
    "#print(xp_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "xr = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "xp = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xp\")\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "model = MyModel(10)\n",
    "\n",
    "output_logits_real, output_real = model.basic_cnn(xr)\n",
    "output_logits_fake, output_fake = model.basic_cnn(xp, reuse=True)\n",
    "\n",
    "# custom loss\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "gama = 0.01\n",
    "loss_r = alpha * tf.reduce_mean(tf.reduce_sum(y * output_real, -1))\n",
    "loss_p = beta * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_logits_fake, labels=y))\n",
    "loss_d = gama * tf.reduce_mean(tf.square(xr - xp))\n",
    "\n",
    "total_loss = loss_r+loss_p+loss_d\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 10000, 0.1, staircase=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss)\n",
    "#print(tf.all_variables())\n",
    "\n",
    "# calculate accuracy\n",
    "correct_prediction1 = tf.equal(tf.argmax(output_fake,1), tf.argmax(y,1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_real,1), tf.argmax(y,1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099996105 2.3025718\n",
      "0.09375 0.0625\n",
      "0.07047914 0.1457195\n",
      "0.0703125 0.9609375\n",
      "0.07036947 0.08940869\n",
      "0.0703125 0.96875\n",
      "0.0703171 0.069024675\n",
      "0.0703125 0.9921875\n",
      "0.070314854 0.04973049\n",
      "0.0703125 0.9921875\n",
      "0.07031293 0.04118075\n",
      "0.0703125 0.9921875\n",
      "0.07031261 0.019713888\n",
      "0.0703125 0.9921875\n",
      "0.07031263 0.035902664\n",
      "0.0703125 0.9921875\n",
      "0.070312805 0.01762394\n",
      "0.0703125 0.9921875\n",
      "0.07031299 0.0065770186\n",
      "0.0703125 1.0\n",
      "0.07031425 0.01412046\n",
      "0.0703125 0.9921875\n",
      "0.07031265 0.023084328\n",
      "0.0703125 0.9921875\n",
      "0.07031259 0.0025312603\n",
      "0.0703125 1.0\n",
      "0.07031256 0.026542747\n",
      "0.0703125 0.984375\n",
      "0.0703125 0.0077087046\n",
      "0.0703125 1.0\n",
      "0.07031437 0.025258606\n",
      "0.0703125 0.9921875\n",
      "0.0703125 0.00040847698\n",
      "0.0703125 1.0\n",
      "0.070312575 0.002642321\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00061368186\n",
      "0.0703125 1.0\n",
      "0.07031251 0.026582291\n",
      "0.0703125 0.9921875\n",
      "0.0703125 0.029683864\n",
      "0.0703125 0.9921875\n",
      "0.0703125 0.00010970449\n",
      "0.0703125 1.0\n",
      "0.0703125 0.000718014\n",
      "0.0703125 1.0\n",
      "0.0703125 3.8901202e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00042018236\n",
      "0.0703125 1.0\n",
      "0.07031252 6.0612496e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0009561171\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00764879\n",
      "0.0703125 0.9921875\n",
      "0.0703125 0.0008726693\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00038955238\n",
      "0.0703125 1.0\n",
      "0.0703125 0.002305218\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0014368079\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00028533477\n",
      "0.0703125 1.0\n",
      "0.0703125 3.8985592e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00088813854\n",
      "0.0703125 1.0\n",
      "0.0703125 2.1383252e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00023569494\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00019957154\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0028135115\n",
      "0.0703125 1.0\n",
      "0.0703125 2.5536461e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 2.0290063e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00016323356\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0002044667\n",
      "0.0703125 1.0\n",
      "0.0703125 2.6666832e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 2.6507021e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.018226374\n",
      "0.0703125 0.9921875\n",
      "0.0703125 0.00012345077\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0004160815\n",
      "0.0703125 1.0\n",
      "0.0703125 4.8070775e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 1.0858728e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 0.031742394\n",
      "0.0703125 0.9921875\n",
      "0.0703125 2.1997876e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0012698381\n",
      "0.0703125 1.0\n",
      "0.0703125 6.211806e-07\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00011917144\n",
      "0.0703125 1.0\n",
      "0.0703125 8.750595e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00057390134\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0001590232\n",
      "0.0703125 1.0\n",
      "0.0703125 0.0028749653\n",
      "0.0703125 1.0\n",
      "0.0703125 6.5669865e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 1.1873612e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 9.275767e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 8.425942e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 6.776481e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 5.911689e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 6.842844e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 5.33849e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 2.5793144e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 2.793966e-08\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00245253\n",
      "0.0703125 1.0\n",
      "0.0703125 4.0410296e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 4.7489946e-05\n",
      "0.0703125 1.0\n",
      "0.0703125 0.00076354697\n",
      "0.0703125 1.0\n",
      "0.0703125 3.362578e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 0.038882554\n",
      "0.0703125 0.9921875\n",
      "0.0703125 2.992983e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 9.145101e-07\n",
      "0.0703125 1.0\n",
      "0.0703125 7.3105605e-07\n",
      "0.0703125 1.0\n",
      "0.0703125 3.6034571e-06\n",
      "0.0703125 1.0\n",
      "0.0703125 4.712063e-05\n",
      "0.0703125 1.0\n"
     ]
    }
   ],
   "source": [
    "total_batch = int(xr_train.shape[0] / BATCH_SIZE)\n",
    "# T_loss = open('out/acc_loss/fixed_total_loss.txt','w+')\n",
    "# D_loss = open('out/acc_loss/fixed_r_loss.txt','w+')\n",
    "# G_loss = open('out/acc_loss/fixed_p_loss.txt','w+')\n",
    "for epoch in range(80):\n",
    "    for i in range(total_batch):\n",
    "        bstart, bend = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "        batch_xr, batch_xp = xr_train[bstart:bend], xp_train[bstart:bend]\n",
    "        batch_yp = yr_train[bstart:bend]\n",
    "\n",
    "        _, t_loss, temp_loss1, temp_loss2, temp_acc1, temp_acc2 = sess.run([optimizer,total_loss,loss_r,loss_p,accuracy2,accuracy1],\n",
    "                                   feed_dict={xr: batch_xr,\n",
    "                                              xp: batch_xp,\n",
    "                                              y: batch_yp})\n",
    "        if i % 2000 == 0:\n",
    "            print(temp_loss1, temp_loss2)\n",
    "            print(temp_acc1,temp_acc2)\n",
    "#         T_loss.write(str(t_loss)+'\\n')\n",
    "#         D_loss.write(str(temp_loss1)+'\\n')\n",
    "#         G_loss.write(str(temp_loss2)+'\\n')\n",
    "# T_loss.close()\n",
    "# D_loss.close()\n",
    "# G_loss.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./savemodel/cnn/cnnmodel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.tables_initializer())\n",
    "# # saver.save(sess,\"./savemodel/cnn/cnnmodel.ckpt\")\n",
    "# saver.save(sess,\"./savemodel/cnn/cnnmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./savemodel/cnn/cnn_fixed.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # save model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess,\"./savemodel/cnn/cnn_fixed.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input accuracy 0.0974\n",
      "processed input accuracy 0.9903\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     tf.global_variables_initializer().run()\n",
    "print(\"raw input accuracy %g\"       %accuracy2.eval(session=sess, feed_dict={xr: xr_test, y: yr_test}))\n",
    "print(\"processed input accuracy %g\" %accuracy1.eval(session=sess, feed_dict={xp: xp_test, y: yr_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate adversarial examples using CleverHans\n",
    "note that the session is still open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM\n",
    "we can modeified parameter \"eps\" to get different adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:33: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n",
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:130: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 2000\n",
      "Iteration 4000\n",
      "Iteration 6000\n",
      "Iteration 8000\n",
      "Iteration 10000\n",
      "Iteration 12000\n",
      "Iteration 14000\n",
      "Iteration 16000\n",
      "Iteration 18000\n",
      "Iteration 20000\n",
      "Iteration 22000\n",
      "Iteration 24000\n",
      "Iteration 26000\n",
      "Iteration 28000\n",
      "Iteration 30000\n",
      "Iteration 32000\n",
      "Iteration 34000\n",
      "Iteration 36000\n",
      "Iteration 38000\n",
      "Iteration 40000\n",
      "Iteration 42000\n",
      "Iteration 44000\n",
      "Iteration 46000\n",
      "Iteration 48000\n",
      "Iteration 50000\n",
      "Iteration 52000\n",
      "Iteration 54000\n",
      "Iteration 56000\n",
      "Iteration 58000\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "attack_model = CNN('cnn', 10)\n",
    "NUM_CLASSES = 10\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "fgsm_params = {\n",
    "    'eps': 0.05,\n",
    "    'clip_min': 0,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': target_class\n",
    "}\n",
    "it = 10 # iterative FGSM\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#   sess.run(init)\n",
    "fgsm = FastGradientMethod(attack_model, sess=sess)\n",
    "x_adv = fgsm.generate(x, **fgsm_params)\n",
    "#   saver = tf.train.Saver()\n",
    "#   saver.restore(sess, './savemodel/cnn/cnnmodel.ckpt')\n",
    "#   saver = tf.train.import_meta_graph('./savemodel/cnn/cnnmodel.meta')\n",
    "#   saver.restore(sess,tf.train.latest_checkpoint('./savemodel/cnn/'))\n",
    "adv_images = np.zeros((60000,28,28,1))\n",
    "for j in range(60000): # np.shape(xr_train)[0]=60000\n",
    "    adv_images[j] = xr_train[j].reshape(-1,28,28,1)\n",
    "    if j%2000==0:\n",
    "        print(\"Iteration \"+str(j))\n",
    "    for i in range(it):\n",
    "        adv_images[j] = sess.run(x_adv, feed_dict={x: adv_images[j].reshape(-1,28,28,1)}) #xr_train[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(adv_images[3].reshape(-1,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9944\n"
     ]
    }
   ],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "_, output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_adv, -1), tf.argmax(target_class, -1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "print(\"test accuracy %g\" %accuracy2.eval(session=sess, feed_dict={adv:adv_images}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn a surragate ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_generator(inputs, reuse=False):\n",
    "    with tf.variable_scope(\"surrogate_generator\", reuse=reuse) as scope:\n",
    "        x = conv2d(inputs, 32,5,5,1,1, name='conv1')\n",
    "        x = conv2d(x, 16,1,1,1,1, name='bottleconv')\n",
    "        x = conv2d(x, 16,3,3,1,1, name='conv2')\n",
    "        x = conv2d(x, 32,1,1,1,1, name='conv3')\n",
    "        x = slim.flatten(x, scope='flatten')\n",
    "        xl = slim.fully_connected(x, 784, activation_fn=None, scope='fc')\n",
    "        xl = tf.reshape(xl,[-1,28,28,1])\n",
    "        # xl = linear(x, 1, scope='fc')\n",
    "        xl = inputs + xl\n",
    "        xp = tf.nn.tanh(xl)\n",
    "        x_logits = slim.fully_connected(slim.dropout(x, 0.5), 10, activation_fn=None, scope='fc2')\n",
    "        x_logits = tf.nn.softmax(x_logits, name=\"softmax\")\n",
    "        # xl = tf.reshape(xl,[-1,28,28,1])\n",
    "        return x_logits, xp\n",
    "\n",
    "# define model\n",
    "_xr  = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "_adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "_y   = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "gen_adv_logits, gen_adv = surrogate_generator(_xr)\n",
    "\n",
    "_loss_label = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=gen_adv_logits, labels=_y))\n",
    "_loss_image = tf.reduce_mean(tf.square(_adv - gen_adv))\n",
    "_total_loss = tf.add(_loss_label, _loss_image)\n",
    "\n",
    "# learning rate\n",
    "_global_step = tf.Variable(0, trainable=False)   \n",
    "_lr_decayed = tf.train.exponential_decay(0.001, _global_step, 2*10000, 0.1, staircase=False)\n",
    "\n",
    "# variable list\n",
    "_all_var = tf.global_variables()\n",
    "_g_vars = [var for var in _all_var if 'generator' in var.name]\n",
    "# optimizer\n",
    "_G_optimizer = tf.train.AdamOptimizer(learning_rate=_lr_decayed).minimize(_total_loss, var_list=[_g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.325075 2.3025851 0.02248982\n",
      "1.4745941 1.46122 0.013374127\n",
      "1.4744276 1.4612198 0.013207832\n",
      "1.4743084 1.4612073 0.013101152\n",
      "1.4742287 1.4611992 0.013029584\n",
      "1.4741738 1.4611955 0.012978309\n",
      "1.4741235 1.4611905 0.012933035\n",
      "1.4740702 1.4611893 0.0128808655\n",
      "1.4739826 1.4611781 0.012804533\n",
      "1.4738605 1.461169 0.012691489\n",
      "1.4737394 1.4611676 0.012571792\n",
      "1.4736406 1.461169 0.012471572\n",
      "1.4735799 1.4611709 0.012408935\n",
      "1.47354 1.461173 0.012366916\n",
      "1.4735221 1.4611664 0.012355667\n",
      "1.4734994 1.4611703 0.012329061\n",
      "1.4734455 1.4611775 0.012268075\n",
      "1.4734057 1.4611773 0.012228326\n",
      "1.4733716 1.461183 0.012188629\n",
      "1.4733448 1.4611871 0.012157711\n",
      "1.473311 1.4611813 0.012129608\n",
      "1.4732903 1.461183 0.012107428\n",
      "1.4732721 1.4611847 0.012087341\n",
      "1.4732438 1.4611753 0.012068481\n",
      "1.4732038 1.4611676 0.012036223\n",
      "1.4731714 1.4611663 0.012005046\n",
      "1.4731394 1.4611759 0.011963477\n",
      "1.4730768 1.4611688 0.011908039\n",
      "1.4730173 1.461165 0.011852349\n",
      "1.4729915 1.4611653 0.011826141\n",
      "1.4729574 1.4611666 0.011790788\n",
      "1.4728998 1.4611603 0.011739529\n",
      "1.4728482 1.4611607 0.01168749\n",
      "1.4728225 1.461163 0.011659523\n",
      "1.4727873 1.4611572 0.011630051\n",
      "1.4727597 1.4611555 0.011604163\n",
      "1.4727353 1.4611566 0.011578726\n",
      "1.4727149 1.461154 0.011560888\n",
      "1.4727013 1.4611566 0.011544695\n",
      "1.4726902 1.4611542 0.011535998\n",
      "1.4726679 1.4611552 0.011512759\n",
      "1.4726616 1.4611547 0.011506862\n",
      "1.4726475 1.4611557 0.011491867\n",
      "1.4726222 1.4611552 0.011466937\n",
      "1.4726398 1.4611541 0.011485684\n",
      "1.4726151 1.4611547 0.011460377\n",
      "1.4725938 1.4611528 0.011441015\n",
      "1.4725919 1.4611526 0.01143934\n",
      "1.472581 1.4611516 0.011429488\n",
      "1.4725705 1.4611518 0.011418741\n",
      "1.4725798 1.4611516 0.011428272\n",
      "1.4725809 1.4611511 0.011429788\n",
      "1.4726017 1.4611509 0.011450795\n",
      "1.4725791 1.4611506 0.011428453\n",
      "1.4725885 1.4611509 0.01143767\n",
      "1.4726093 1.4611508 0.011458561\n",
      "1.4726095 1.4611506 0.011458898\n",
      "1.472623 1.4611505 0.011472408\n",
      "1.472655 1.4611504 0.0115046315\n",
      "1.4726852 1.4611504 0.011534867\n",
      "1.4726374 1.4611504 0.011486956\n",
      "1.4726124 1.4611504 0.01146195\n",
      "1.4725972 1.4611502 0.011447125\n",
      "1.4725505 1.4611504 0.0114001315\n",
      "1.4725535 1.4611503 0.011403206\n",
      "1.4725034 1.4611502 0.011353239\n",
      "1.4724791 1.4611502 0.011328954\n",
      "1.4724855 1.4611502 0.011335357\n",
      "1.4724629 1.4611502 0.011312699\n",
      "1.4724666 1.4611502 0.011316439\n",
      "1.4725101 1.4611502 0.011359971\n",
      "1.4725817 1.4611502 0.011431584\n",
      "1.4727263 1.4611502 0.011576192\n",
      "1.4726926 1.4611502 0.011542468\n",
      "1.4726723 1.4611502 0.011522165\n",
      "1.4726555 1.4611502 0.011505338\n",
      "1.4726272 1.4611502 0.011476967\n",
      "1.4726088 1.4611502 0.011458582\n",
      "1.4726049 1.4611502 0.011454746\n",
      "1.4725735 1.4611502 0.011423317\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.tables_initializer())\n",
    "\n",
    "target_label = sess.run(target_class)\n",
    "\n",
    "# BATCH_SIZE = 128\n",
    "_total_batch = int(60000 / BATCH_SIZE)\n",
    "# T_loss = open('out/acc_loss/fixed_total_loss.txt','w+')\n",
    "# D_loss = open('out/acc_loss/fixed_r_loss.txt','w+')\n",
    "# G_loss = open('out/acc_loss/fixed_p_loss.txt','w+')\n",
    "for epoch in range(80):\n",
    "    for i in range(_total_batch):\n",
    "        bstart, bend = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "        batch_xr, batch_xp = xr_train[bstart:bend], adv_images[bstart:bend]\n",
    "        batch_y = np.repeat(target_label, BATCH_SIZE, axis=0)\n",
    "\n",
    "        _, G_loss_curr, _loss_l, _loss_i = sess.run([_G_optimizer, _total_loss, _loss_label, _loss_image],\n",
    "                                  feed_dict={_xr: batch_xr,\n",
    "                                             _adv: batch_xp,\n",
    "                                             _y: batch_y})\n",
    "        if i % 1000 == 0:\n",
    "            print(G_loss_curr, _loss_l, _loss_i)\n",
    "#     T_loss.write(str(t_loss)+'\\n')\n",
    "#     D_loss.write(str(temp_loss1)+'\\n')\n",
    "#     G_loss.write(str(temp_loss2)+'\\n')\n",
    "# T_loss.close()\n",
    "# D_loss.close()\n",
    "# G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed adversarial accuracy 1\n"
     ]
    }
   ],
   "source": [
    "_xin = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xin\")\n",
    "# _y  = tf.placeholder(tf.float32, [None, 10])\n",
    "target_label = sess.run(target_class)\n",
    "\n",
    "_gen_adv_logits, _gen_adv = surrogate_generator(_xin, reuse=True)\n",
    "\n",
    "# g_sample = sess.run(_gen_adv, feed_dict={_xin: xr_test[0].reshape(-1,28,28,1)})\n",
    "# plt.imshow(g_sample.reshape(-1,28))\n",
    "\n",
    "# calculate accuracy\n",
    "_correct_prediction = tf.equal(tf.argmax(_gen_adv_logits, axis=-1), tf.argmax(target_class, axis=-1))\n",
    "_accuracy_fake = tf.reduce_mean(tf.cast(_correct_prediction, \"float\"))\n",
    "\n",
    "print(\"fixed adversarial accuracy %g\" %_accuracy_fake.eval(session=sess, feed_dict={_xin: xr_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6324135c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_sample = sess.run(_gen_adv, feed_dict={_xin: xr_test[0].reshape(-1,28,28,1)})\n",
    "plt.imshow(g_sample.reshape(-1,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data as tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    target_label = session.run(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./out/adv_fixed_mnist.tfrecords\"\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "for i in range(50000):\n",
    "    images_raw = adv_images[i].tostring()\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'label': _int64_feature(np.argmax(target_label)),\n",
    "        'image': _bytes_feature(images_raw)}))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# for i in range(50000):\n",
    "#     im = adv_images[i].reshape(28,28)\n",
    "#     img= Image.fromarray(im*255)\n",
    "#     img = img.convert('RGB')\n",
    "#     img.save('out/adversarial/fixed/3/adv_%s.png'%i,'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculation (TODO)\n",
    "we can use FGSM method which written by ourselves to generate adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_fgsm(x, eps, logits):\n",
    "    label = tf.argmax(logits,1)\n",
    "    one_hot_label = tf.one_hot(label, NUM_CLASSES)\n",
    "    cross_entropy = tf.losses.softmax_cross_entropy(one_hot_label,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "    x_adv = x + eps*tf.sign(tf.gradients(cross_entropy,x)[0])\n",
    "    x_adv = tf.clip_by_value(x_adv,-1.0,1.0)\n",
    "    return tf.stop_gradient(x_adv)\n",
    " \n",
    "def step_targeted_attack(x, eps, one_hot_target_class, logits):\n",
    "    #one_hot_target_class = tf.one_hot(target, NUM_CLASSES)\n",
    "    #print(one_hot_target_class,\"\\n\\n\")\n",
    "    cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "    x_adv = x - eps * tf.sign(tf.gradients(cross_entropy, x)[0])\n",
    "    x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "    return tf.stop_gradient(x_adv)\n",
    "\n",
    "def step_ll_adversarial_images(x, eps, logits):\n",
    "    least_likely_class = tf.argmin(logits, 1)\n",
    "    one_hot_ll_class = tf.one_hot(least_likely_class, NUM_CLASSES)\n",
    "    one_hot_ll_class = tf.reshape(one_hot_ll_class,[1,NUM_CLASSES])\n",
    "    # This reuses the method described above\n",
    "    return step_targeted_attack(x, eps, one_hot_ll_class, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_tensor = sess.graph.get_tensor_by_name('discriminator/fc2/add:0')\n",
    "image_tensor = sess.graph.get_tensor_by_name('xr:0')\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "\n",
    "adv_image_tensor = step_targeted_attack(image_tensor, fgsm_params['eps'], target_class, softmax_tensor)\n",
    "adv_image = xr_train[0].reshape(-1,28,28,1)\n",
    "t = adv_image.copy()\n",
    "adv_noise = np.zeros(t.shape)\n",
    "# for j in range(100):\n",
    "j=0\n",
    "adv_image = xr_train[j].reshape(-1,28,28,1)\n",
    "if j%2000==0:\n",
    "    print(\"Iteration \"+str(j))\n",
    "for i in range(it):\n",
    "    #print(\"Iteration \"+str(i))\n",
    "    adv_image = sess.run(adv_image_tensor,{'xr:0': adv_image})\n",
    "adv_noise = np.concatenate((adv_noise, adv_image))\n",
    "#plt.imshow(adv_image.reshape(-1,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adv_image[0].reshape(-1,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "output_logits_adv, output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_adv, -1), tf.argmax(target_class, -1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "print(\"test accuracy %g\" %accuracy2.eval(session=sess, feed_dict={adv:adv_images}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type             Data/Info\n",
      "------------------------------------------------\n",
      "BATCH_SIZE            int              128\n",
      "CIFAR10               type             <class 'cleverhans.dataset.CIFAR10'>\n",
      "CNN                   type             <class 'model.CNN'>\n",
      "CarliniWagnerL2       type             <class 'cleverhans.attacks.CarliniWagnerL2'>\n",
      "D_loss                TextIOWrapper    <_io.TextIOWrapper name='<...>de='w+' encoding='UTF-8'>\n",
      "FastGradientMethod    type             <class 'cleverhans.attacks.FastGradientMethod'>\n",
      "G_loss                TextIOWrapper    <_io.TextIOWrapper name='<...>de='w+' encoding='UTF-8'>\n",
      "MNIST                 type             <class 'cleverhans.dataset.MNIST'>\n",
      "MyModel               type             <class 'model.MyModel'>\n",
      "NB_EPOCHS             int              100\n",
      "T_loss                TextIOWrapper    <_io.TextIOWrapper name='<...>de='w+' encoding='UTF-8'>\n",
      "accuracy1             Tensor           Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "accuracy2             Tensor           Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "alpha                 float            1.0\n",
      "batch_xp              ndarray          128x28x28x1: 100352 elems, type `float32`, 401408 bytes (392.0 kb)\n",
      "batch_xr              ndarray          128x28x28x1: 100352 elems, type `float32`, 401408 bytes (392.0 kb)\n",
      "batch_yp              ndarray          128x10: 1280 elems, type `float32`, 5120 bytes\n",
      "bend                  int              59904\n",
      "beta                  float            1.0\n",
      "bstart                int              59776\n",
      "correct_prediction1   Tensor           Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "correct_prediction2   Tensor           Tensor(\"Equal_1:0\", shape=(?,), dtype=bool)\n",
      "epoch                 int              79\n",
      "fixed_pattern         function         <function fixed_pattern at 0x7f4c88a538c8>\n",
      "gama                  float            0.01\n",
      "generator             function         <function generator at 0x7f4c88a53bf8>\n",
      "global_step           Variable         <tf.Variable 'Variable:0'<...>shape=() dtype=int32_ref>\n",
      "i                     int              467\n",
      "loss_d                Tensor           Tensor(\"mul_3:0\", shape=(), dtype=float32)\n",
      "loss_p                Tensor           Tensor(\"mul_2:0\", shape=(), dtype=float32)\n",
      "loss_r                Tensor           Tensor(\"mul_1:0\", shape=(), dtype=float32)\n",
      "lr_decayed            Tensor           Tensor(\"ExponentialDecay:<...> shape=(), dtype=float32)\n",
      "mnist                 MNIST            <cleverhans.dataset.MNIST<...>object at 0x7f4c88a51cf8>\n",
      "model                 MyModel          <model.MyModel object at 0x7f4c85e114e0>\n",
      "nb_classes            int              10\n",
      "nb_filters            int              64\n",
      "np                    module           <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "optimizer             Operation        name: \"Adam\"\\nop: \"NoOp\"\\<...>input: \"^Adam/Assign_1\"\\n\n",
      "os                    module           <module 'os' from '/home/<...>y35/lib/python3.5/os.py'>\n",
      "output_fake           Tensor           Tensor(\"discriminator_1/s<...>e=(?, 10), dtype=float32)\n",
      "output_logits_fake    Tensor           Tensor(\"discriminator_1/f<...>e=(?, 10), dtype=float32)\n",
      "output_logits_real    Tensor           Tensor(\"discriminator/fc2<...>e=(?, 10), dtype=float32)\n",
      "output_real           Tensor           Tensor(\"discriminator/sof<...>e=(?, 10), dtype=float32)\n",
      "pattern               ndarray          28x28x1: 784 elems, type `float64`, 6272 bytes\n",
      "probability           list             n=3\n",
      "saver                 Saver            <tensorflow.python.traini<...>object at 0x7f4c88a517f0>\n",
      "sess                  Session          <tensorflow.python.client<...>object at 0x7f4c88a518d0>\n",
      "sigma                 list             n=3\n",
      "t_loss                float32          0.07816679\n",
      "temp_acc1             float32          0.078125\n",
      "temp_acc2             float32          1.0\n",
      "temp_loss1            float32          0.078125\n",
      "temp_loss2            float32          8.38189e-08\n",
      "test_end              int              10000\n",
      "test_start            int              0\n",
      "tf                    module           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "total_batch           int              468\n",
      "total_loss            Tensor           Tensor(\"add_1:0\", shape=(), dtype=float32)\n",
      "train_end             int              60000\n",
      "train_start           int              0\n",
      "xp                    Tensor           Tensor(\"xp:0\", shape=(?, <...>8, 28, 1), dtype=float32)\n",
      "xp_test               ndarray          10000x28x28x1: 7840000 elems, type `float32`, 31360000 bytes (29.9072265625 Mb)\n",
      "xp_train              ndarray          60000x28x28x1: 47040000 elems, type `float32`, 188160000 bytes (179.443359375 Mb)\n",
      "xr                    Tensor           Tensor(\"xr:0\", shape=(?, <...>8, 28, 1), dtype=float32)\n",
      "xr_test               ndarray          10000x28x28x1: 7840000 elems, type `float32`, 31360000 bytes (29.9072265625 Mb)\n",
      "xr_train              ndarray          60000x28x28x1: 47040000 elems, type `float32`, 188160000 bytes (179.443359375 Mb)\n",
      "y                     Tensor           Tensor(\"Placeholder:0\", s<...>e=(?, 10), dtype=float32)\n",
      "yr_test               ndarray          10000x10: 100000 elems, type `float32`, 400000 bytes (390.625 kb)\n",
      "yr_train              ndarray          60000x10: 600000 elems, type `float32`, 2400000 bytes (2.288818359375 Mb)\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
