{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "import perturbation as pb\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "(fr_train_images, fr_train_labels), \\\n",
    "(fr_test_images, fr_test_labels) = fashion_mnist.load_data()\n",
    "mnist_raw = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\" # mnist fashion\n",
    "network = \"cnn\"     # cnn resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"mnist\":\n",
    "  X_raw_train = mnist_raw.train.images\n",
    "  Y_raw_train = mnist_raw.train.labels\n",
    "  X_raw_test  = mnist_raw.test.images\n",
    "  Y_raw_test  = mnist_raw.test.labels\n",
    "elif dataset == \"fashion\":\n",
    "  frx_train = fr_train_images.reshape(fr_train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  fry_test  = fr_test_images.reshape(fr_test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_raw_train  = frx_train/255\n",
    "  Y_raw_train  = np_utils.to_categorical(fr_train_labels)\n",
    "  X_raw_test   = fry_test/255\n",
    "  Y_raw_test   = np_utils.to_categorical(fr_test_labels)\n",
    "  num_examples = fr_train_images.shape[0]\n",
    "  pattern      = np.reshape(pattern, (28, 28, 1))\n",
    "  fpx_train    = np.zeros(X_raw_train.shape)\n",
    "  fpx_test     = np.zeros(X_raw_test.shape)\n",
    "\n",
    "  for i in range(0, fr_train_images.shape[0]):\n",
    "    fpx_train[i] = X_raw_train[i] + pattern\n",
    "  for i in range(0, fr_test_images.shape[0]):\n",
    "    fpx_test[i] = X_raw_test[i] + pattern\n",
    "  X_process_train = fpx_train\n",
    "  Y_process_train = Y_raw_train\n",
    "  X_process_test  = fpx_test\n",
    "  Y_process_test  = Y_raw_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "X_r = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "Y_r = tf.placeholder(tf.float32, [None, 10])\n",
    "# X_p = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xp\")\n",
    "Y_p = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(10)\n",
    "# generate perturbation according to the input\n",
    "_, G_sample = pb.generator(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if network == \"cnn\":\n",
    "  output_logits_real, output_real = model.basic_cnn(X_r)\n",
    "  output_logits_fake, output_fake = model.basic_cnn(G_sample,reuse=True)\n",
    "elif network == \"resnet\":\n",
    "  output_logits_real, output_real = model.resnet20(X_r)\n",
    "  output_logits_fake, output_fake = model.resnet20(G_sample,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "gama = 10.\n",
    "loss_r = alpha * tf.reduce_mean(tf.reduce_sum(Y_r * output_real, -1))\n",
    "loss_p = beta * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_logits_fake, labels=Y_p))\n",
    "loss_d = gama * tf.reduce_mean(tf.square(X_r - G_sample))\n",
    "loss_p_d =  tf.add(loss_p, loss_d)\n",
    "total_loss = loss_r+loss_p+loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "global_step = tf.Variable(0, trainable=False)   \n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 2*10000, 0.1, staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-71f8942828ea>:2: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "# variable list\n",
    "all_var = tf.all_variables()\n",
    "g_vars = [var for var in all_var if 'generator' in var.name]\n",
    "d_vars = [var for var in all_var if 'discriminator' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss, var_list=[d_vars])\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(loss_p_d, var_list=[g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 2.453\n",
      "G_loss: 2.351\n",
      "\n",
      "Iter: 400\n",
      "D loss: 0.3543\n",
      "G_loss: 0.1914\n",
      "\n",
      "Iter: 800\n",
      "D loss: 0.3111\n",
      "G_loss: 0.1563\n",
      "\n",
      "Iter: 1200\n",
      "D loss: 0.1969\n",
      "G_loss: 0.1382\n",
      "\n",
      "Iter: 1600\n",
      "D loss: 0.1889\n",
      "G_loss: 0.09676\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.2506\n",
      "G_loss: 0.124\n",
      "\n",
      "Iter: 2400\n",
      "D loss: 0.1992\n",
      "G_loss: 0.08369\n",
      "\n",
      "Iter: 2800\n",
      "D loss: 0.2038\n",
      "G_loss: 0.06502\n",
      "\n",
      "Iter: 3200\n",
      "D loss: 0.2042\n",
      "G_loss: 0.1365\n",
      "\n",
      "Iter: 3600\n",
      "D loss: 0.1744\n",
      "G_loss: 0.04458\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.1278\n",
      "G_loss: 0.04788\n",
      "\n",
      "Iter: 4400\n",
      "D loss: 0.18\n",
      "G_loss: 0.03988\n",
      "\n",
      "Iter: 4800\n",
      "D loss: 0.1228\n",
      "G_loss: 0.04897\n",
      "\n",
      "Iter: 5200\n",
      "D loss: 0.1706\n",
      "G_loss: 0.04785\n",
      "\n",
      "Iter: 5600\n",
      "D loss: 0.1371\n",
      "G_loss: 0.03581\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.1305\n",
      "G_loss: 0.04168\n",
      "\n",
      "Iter: 6400\n",
      "D loss: 0.1048\n",
      "G_loss: 0.04797\n",
      "\n",
      "Iter: 6800\n",
      "D loss: 0.1774\n",
      "G_loss: 0.03709\n",
      "\n",
      "Iter: 7200\n",
      "D loss: 0.1757\n",
      "G_loss: 0.03989\n",
      "\n",
      "Iter: 7600\n",
      "D loss: 0.1269\n",
      "G_loss: 0.07778\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.0973\n",
      "G_loss: 0.06359\n",
      "\n",
      "Iter: 8400\n",
      "D loss: 0.1059\n",
      "G_loss: 0.04121\n",
      "\n",
      "Iter: 8800\n",
      "D loss: 0.1578\n",
      "G_loss: 0.04504\n",
      "\n",
      "Iter: 9200\n",
      "D loss: 0.1319\n",
      "G_loss: 0.03555\n",
      "\n",
      "Iter: 9600\n",
      "D loss: 0.09419\n",
      "G_loss: 0.03318\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.1396\n",
      "G_loss: 0.03842\n",
      "\n",
      "Iter: 10400\n",
      "D loss: 0.1394\n",
      "G_loss: 0.03005\n",
      "\n",
      "Iter: 10800\n",
      "D loss: 0.1325\n",
      "G_loss: 0.03158\n",
      "\n",
      "Iter: 11200\n",
      "D loss: 0.1085\n",
      "G_loss: 0.03235\n",
      "\n",
      "Iter: 11600\n",
      "D loss: 0.1645\n",
      "G_loss: 0.03169\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.1685\n",
      "G_loss: 0.02658\n",
      "\n",
      "Iter: 12400\n",
      "D loss: 0.08244\n",
      "G_loss: 0.02777\n",
      "\n",
      "Iter: 12800\n",
      "D loss: 0.1213\n",
      "G_loss: 0.02958\n",
      "\n",
      "Iter: 13200\n",
      "D loss: 0.1083\n",
      "G_loss: 0.04831\n",
      "\n",
      "Iter: 13600\n",
      "D loss: 0.145\n",
      "G_loss: 0.02874\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.1568\n",
      "G_loss: 0.05875\n",
      "\n",
      "Iter: 14400\n",
      "D loss: 0.1072\n",
      "G_loss: 0.02922\n",
      "\n",
      "Iter: 14800\n",
      "D loss: 0.1409\n",
      "G_loss: 0.02738\n",
      "\n",
      "Iter: 15200\n",
      "D loss: 0.1375\n",
      "G_loss: 0.02814\n",
      "\n",
      "Iter: 15600\n",
      "D loss: 0.1454\n",
      "G_loss: 0.02654\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.1324\n",
      "G_loss: 0.03525\n",
      "\n",
      "Iter: 16400\n",
      "D loss: 0.1302\n",
      "G_loss: 0.02842\n",
      "\n",
      "Iter: 16800\n",
      "D loss: 0.1023\n",
      "G_loss: 0.05415\n",
      "\n",
      "Iter: 17200\n",
      "D loss: 0.09695\n",
      "G_loss: 0.04401\n",
      "\n",
      "Iter: 17600\n",
      "D loss: 0.1232\n",
      "G_loss: 0.03376\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.121\n",
      "G_loss: 0.02679\n",
      "\n",
      "Iter: 18400\n",
      "D loss: 0.1894\n",
      "G_loss: 0.02543\n",
      "\n",
      "Iter: 18800\n",
      "D loss: 0.09684\n",
      "G_loss: 0.03442\n",
      "\n",
      "Iter: 19200\n",
      "D loss: 0.1295\n",
      "G_loss: 0.1047\n",
      "\n",
      "Iter: 19600\n",
      "D loss: 0.1194\n",
      "G_loss: 0.02481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "i = 0\n",
    "D_loss = open('out/acc_loss/discriminator_loss.txt','a+')\n",
    "G_loss = open('out/acc_loss/generator_loss.txt','a+')\n",
    "for it in range(20000):\n",
    "  if it % 2000 == 0:\n",
    "    samples = sess.run(G_sample, feed_dict={X_r: X_raw_train[it].reshape(-1,28,28,1)})\n",
    "    samples = (samples / 2 + 0.5)*255\n",
    "    fig = plot(samples)\n",
    "    plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "    cv2.imwrite('out/cv2_{}.png'.format(str(i).zfill(3)), samples.reshape(28,28,1))\n",
    "    i += 1\n",
    "    plt.close(fig)\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  _, D_loss_curr = sess.run([D_optimizer, total_loss],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  _, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "\n",
    "  if it % 400 == 0:\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('D loss: {:.4}'.format(D_loss_curr))\n",
    "    print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "    print()\n",
    "    D_loss.write(str(D_loss_curr)+'\\n')\n",
    "    G_loss.write(str(G_loss_curr)+'\\n')\n",
    "\n",
    "D_loss.close()\n",
    "G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of real data: 0.104\n",
      "accuracy of fake data: 0.999\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(output_fake, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_fake = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(output_real, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_real = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "# test processed input\n",
    "Accuracy_real = np.array([])\n",
    "Accuracy_fake = np.array([])\n",
    "for i in range(1000):\n",
    "    #batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    #batch_xp, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    #batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "    #batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  temp_acc, temp_acc_ = sess.run([accuracy_real,accuracy_fake],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  #_, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "  Accuracy_real = np.insert(Accuracy_real,0, temp_acc)\n",
    "  Accuracy_fake = np.insert(Accuracy_fake,0, temp_acc_)\n",
    "print('accuracy of real data: %.3f' % np.mean(Accuracy_real))\n",
    "print('accuracy of fake data: %.3f' % np.mean(Accuracy_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "def step_fgsm(x, eps, logits):\n",
    "  label = tf.argmax(logits,1)\n",
    "  one_hot_label = tf.one_hot(label, NUM_CLASSES)\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_label,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x + eps*tf.sign(tf.gradients(cross_entropy,x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv,-1.0,1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    " \n",
    "def step_targeted_attack(x, eps, one_hot_target_class, logits):\n",
    "  #one_hot_target_class = tf.one_hot(target, NUM_CLASSES)\n",
    "  #print(one_hot_target_class,\"\\n\\n\")\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x - eps * tf.sign(tf.gradients(cross_entropy, x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    "\n",
    "def step_ll_adversarial_images(x, eps, logits):\n",
    "  least_likely_class = tf.argmin(logits, 1)\n",
    "  one_hot_ll_class = tf.one_hot(least_likely_class, NUM_CLASSES)\n",
    "  one_hot_ll_class = tf.reshape(one_hot_ll_class,[1,NUM_CLASSES])\n",
    "  # This reuses the method described above\n",
    "  return step_targeted_attack(x, eps, one_hot_ll_class, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "#print(mnist_raw.train.images[0])\n",
    "  target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "  out = session.run(target_class)\n",
    "  print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 2000\n",
      "Iteration 4000\n",
      "Iteration 6000\n",
      "Iteration 8000\n",
      "Iteration 10000\n",
      "Iteration 12000\n",
      "Iteration 14000\n",
      "Iteration 16000\n",
      "Iteration 18000\n",
      "Iteration 20000\n",
      "Iteration 22000\n",
      "Iteration 24000\n",
      "Iteration 26000\n",
      "Iteration 28000\n",
      "Iteration 30000\n",
      "Iteration 32000\n",
      "Iteration 34000\n",
      "Iteration 36000\n",
      "Iteration 38000\n",
      "Iteration 40000\n",
      "Iteration 42000\n",
      "Iteration 44000\n",
      "Iteration 46000\n",
      "Iteration 48000\n",
      "Iteration 50000\n",
      "Iteration 52000\n",
      "Iteration 54000\n"
     ]
    }
   ],
   "source": [
    "softmax_tensor = sess.graph.get_tensor_by_name('discriminator/fc2/add:0')\n",
    "image_tensor = sess.graph.get_tensor_by_name('xr:0')\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "\n",
    "adv_image_tensor = step_targeted_attack(image_tensor, 0.007, target_class, softmax_tensor)\n",
    "adv_image = mnist_raw.train.images[0].reshape(-1,28,28,1)\n",
    "t = adv_image.copy()\n",
    "adv_noise = np.zeros(t.shape)\n",
    "for j in range(55000):\n",
    "  adv_image = mnist_raw.train.images[j].reshape(-1,28,28,1)\n",
    "  if j%2000==0:\n",
    "    print(\"Iteration \"+str(j))\n",
    "  for i in range(10):\n",
    "    #print(\"Iteration \"+str(i))\n",
    "    adv_image = sess.run(adv_image_tensor,{'xr:0': adv_image})\n",
    "  adv_noise = np.concatenate((adv_noise, adv_image))\n",
    "#plt.imshow(adv_image.reshape(-1,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(54999):\n",
    "  im = adv_noise[i+1].reshape(28,28)\n",
    "  img= Image.fromarray(im*255)\n",
    "  img = img.convert('RGB')\n",
    "  img.save('out/adversarial/3/adv_%s.png'%i,'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3443a0748>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv_noise[54999].reshape(-1,28))\n",
    "#print(mnist_raw.train.labels[3])\n",
    "#plt.show()\n",
    "#save_image(t,(-1,28,28,1),\"original.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.474719\n"
     ]
    }
   ],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "output_logits_adv, output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_adv, -1), \\\n",
    "        tf.argmax(target_class, -1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "print(\"test accuracy %g\" %accuracy2.eval(session = sess,\n",
    "      feed_dict = {\n",
    "          adv:adv_noise}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
