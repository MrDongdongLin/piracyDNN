{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adversarial attacks on Chen&Wu's scheme\n",
    "In this file, we simulate the process of the _generator approach_ in Chen's scheme [1]. The proposed  framework is capable of keeping the DNNs functional to authorized access while dysfunctional to unauthorized access or illicit use. We do some attacks on it. In the following table, the attack scenarios are listed.\n",
    "\n",
    "Attack scenario | $x_r$ | ATM | $x_p$ | ADNN\n",
    "-|-|-|-|-\n",
    "Black-box attack        | × | × | × | × \n",
    "Black-box with $x_r$     | √ | × | × | ×\n",
    "ATM white-box          | × | √ | × | ×\n",
    "Black-box with $x_p$     | × | × | √ | ×\n",
    "Diract piracy          | × | × | × | √\n",
    "ATM white-box with $x_r$  |  √ | √ | × | ×\n",
    "Pair attack           | √ | × | √ | ×\n",
    "ADNN white-box with $x_r$  | √ | × | × | √\n",
    "ATM white-box with $x_p$  |  × | √ | √ | ×\n",
    "ATM and ADNN white-box    | × | √ | × | √\n",
    "ADNN white-box with $x_p$  | × | × | √ | √\n",
    "ATM white-box & pair attack| √ | √ | √ | ×\n",
    "ATM and ADNN white-box with $x_r$ | √ | √ | × | √\n",
    "ADNN white-box & pair attack    |  √ | × | √ | √\n",
    "ATM and ADNN white-box with $x_p$ | × | √ | √ | √\n",
    "White-box attack | √ | √ | √ | √"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import MyModel, CNN\n",
    "from cleverhans.attacks import FastGradientMethod, CarliniWagnerL2\n",
    "from cleverhans.dataset import MNIST, CIFAR10\n",
    "from keras.datasets import fashion_mnist\n",
    "from perturbation import generator\n",
    "from model import *\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\"\n",
    "network = \"cnn\"\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "xr_train, yr_train = mnist.get_set('train')\n",
    "xr_test, yr_test = mnist.get_set('test')\n",
    "xp_train = xr_train.copy()\n",
    "xp_test = xr_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "xr = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "xp = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xp\")\n",
    "y  = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(10)\n",
    "# generate perturbation according to the input\n",
    "_, G_sample = generator(xr)\n",
    "\n",
    "if network == \"cnn\":\n",
    "    output_logits_real, output_real = model.basic_cnn(xr)\n",
    "    output_logits_fake, output_fake = model.basic_cnn(G_sample,reuse=True)\n",
    "elif network == \"resnet\":\n",
    "    output_logits_real, output_real = model.resnet20(xr)\n",
    "    output_logits_fake, output_fake = model.resnet20(G_sample,reuse=True)\n",
    "# loss\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "gama = 0.01\n",
    "loss_r = alpha * tf.reduce_mean(tf.reduce_sum(y * output_real, -1))\n",
    "loss_p = beta * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_logits_fake, labels=y))\n",
    "loss_d = gama * tf.reduce_mean(tf.square(xr - G_sample))\n",
    "loss_p_d =  tf.add(loss_p, loss_d)\n",
    "total_loss = loss_r+loss_p+loss_d\n",
    "# learning rate\n",
    "global_step = tf.Variable(0, trainable=False)   \n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 2*10000, 0.1, staircase=False)\n",
    "# variable list\n",
    "all_var = tf.global_variables()\n",
    "g_vars = [var for var in all_var if 'generator' in var.name]\n",
    "d_vars = [var for var in all_var if 'discriminator' in var.name]\n",
    "\n",
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss, var_list=[d_vars])\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(loss_p_d, var_list=[g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_loss: 2.403\n",
      "G_loss: 2.3\n",
      "D_loss: 0.2857\n",
      "G_loss: 0.1376\n",
      "D_loss: 0.2223\n",
      "G_loss: 0.08953\n",
      "D_loss: 0.2027\n",
      "G_loss: 0.04866\n",
      "D_loss: 0.2133\n",
      "G_loss: 0.06527\n",
      "D_loss: 0.2221\n",
      "G_loss: 0.04735\n",
      "D_loss: 0.2769\n",
      "G_loss: 0.05185\n",
      "D_loss: 0.2618\n",
      "G_loss: 0.04969\n",
      "D_loss: 0.1973\n",
      "G_loss: 0.04498\n",
      "D_loss: 0.1996\n",
      "G_loss: 0.03129\n",
      "D_loss: 0.1116\n",
      "G_loss: 0.02852\n",
      "D_loss: 0.02696\n",
      "G_loss: 0.03042\n",
      "D_loss: 0.064\n",
      "G_loss: 0.01912\n",
      "D_loss: 0.02853\n",
      "G_loss: 0.01443\n",
      "D_loss: 0.02962\n",
      "G_loss: 0.01479\n",
      "D_loss: 0.01326\n",
      "G_loss: 0.01294\n",
      "D_loss: 0.03267\n",
      "G_loss: 0.01619\n",
      "D_loss: 0.008614\n",
      "G_loss: 0.008772\n",
      "D_loss: 0.01056\n",
      "G_loss: 0.02516\n",
      "D_loss: 0.009405\n",
      "G_loss: 0.01129\n",
      "D_loss: 0.01098\n",
      "G_loss: 0.01017\n",
      "D_loss: 0.008141\n",
      "G_loss: 0.008284\n",
      "D_loss: 0.01911\n",
      "G_loss: 0.01939\n",
      "D_loss: 0.007508\n",
      "G_loss: 0.007327\n",
      "D_loss: 0.01574\n",
      "G_loss: 0.01237\n",
      "D_loss: 0.008739\n",
      "G_loss: 0.02324\n",
      "D_loss: 0.01608\n",
      "G_loss: 0.009345\n",
      "D_loss: 0.01918\n",
      "G_loss: 0.0119\n",
      "D_loss: 0.008992\n",
      "G_loss: 0.01929\n",
      "D_loss: 0.02495\n",
      "G_loss: 0.008615\n",
      "D_loss: 0.007976\n",
      "G_loss: 0.008088\n",
      "D_loss: 0.00881\n",
      "G_loss: 0.01051\n",
      "D_loss: 0.07346\n",
      "G_loss: 0.06007\n",
      "D_loss: 0.009255\n",
      "G_loss: 0.01021\n",
      "D_loss: 0.08587\n",
      "G_loss: 0.1479\n",
      "D_loss: 0.009898\n",
      "G_loss: 0.009404\n",
      "D_loss: 0.01585\n",
      "G_loss: 0.007849\n",
      "D_loss: 0.007825\n",
      "G_loss: 0.00705\n",
      "D_loss: 0.01219\n",
      "G_loss: 0.01057\n",
      "D_loss: 0.01329\n",
      "G_loss: 0.008496\n",
      "D_loss: 0.01049\n",
      "G_loss: 0.01999\n",
      "D_loss: 0.007648\n",
      "G_loss: 0.007795\n",
      "D_loss: 0.009535\n",
      "G_loss: 0.0123\n",
      "D_loss: 0.007014\n",
      "G_loss: 0.007092\n",
      "D_loss: 0.02216\n",
      "G_loss: 0.03382\n",
      "D_loss: 0.01227\n",
      "G_loss: 0.00687\n",
      "D_loss: 0.006841\n",
      "G_loss: 0.007278\n",
      "D_loss: 0.006983\n",
      "G_loss: 0.006333\n",
      "D_loss: 0.01047\n",
      "G_loss: 0.006199\n",
      "D_loss: 0.009204\n",
      "G_loss: 0.007097\n",
      "D_loss: 0.008135\n",
      "G_loss: 0.007188\n",
      "D_loss: 0.02905\n",
      "G_loss: 0.008391\n",
      "D_loss: 0.006756\n",
      "G_loss: 0.006266\n",
      "D_loss: 0.02716\n",
      "G_loss: 0.01015\n",
      "D_loss: 0.03427\n",
      "G_loss: 0.006529\n",
      "D_loss: 0.006722\n",
      "G_loss: 0.006891\n",
      "D_loss: 0.0209\n",
      "G_loss: 0.008703\n",
      "D_loss: 0.007671\n",
      "G_loss: 0.00633\n",
      "D_loss: 0.007903\n",
      "G_loss: 0.006466\n",
      "D_loss: 0.01477\n",
      "G_loss: 0.02646\n",
      "D_loss: 0.006604\n",
      "G_loss: 0.006456\n",
      "D_loss: 0.007121\n",
      "G_loss: 0.006895\n",
      "D_loss: 0.06676\n",
      "G_loss: 0.03083\n",
      "D_loss: 0.006581\n",
      "G_loss: 0.006565\n",
      "D_loss: 0.005701\n",
      "G_loss: 0.005675\n",
      "D_loss: 0.005535\n",
      "G_loss: 0.005525\n",
      "D_loss: 0.007246\n",
      "G_loss: 0.005421\n",
      "D_loss: 0.01015\n",
      "G_loss: 0.00713\n",
      "D_loss: 0.006839\n",
      "G_loss: 0.006834\n",
      "D_loss: 0.009817\n",
      "G_loss: 0.01056\n",
      "D_loss: 0.006712\n",
      "G_loss: 0.006712\n",
      "D_loss: 0.005834\n",
      "G_loss: 0.00581\n",
      "D_loss: 0.005686\n",
      "G_loss: 0.005687\n",
      "D_loss: 0.006224\n",
      "G_loss: 0.006213\n",
      "D_loss: 0.005304\n",
      "G_loss: 0.005304\n",
      "D_loss: 0.005964\n",
      "G_loss: 0.005875\n",
      "D_loss: 0.005472\n",
      "G_loss: 0.005633\n",
      "D_loss: 0.09863\n",
      "G_loss: 0.0588\n",
      "D_loss: 0.006935\n",
      "G_loss: 0.005982\n",
      "D_loss: 0.006453\n",
      "G_loss: 0.006453\n"
     ]
    }
   ],
   "source": [
    "total_batch = int(xr_train.shape[0] / BATCH_SIZE)\n",
    "# D_loss = open('out/acc_loss/discriminator_loss.txt','w+')\n",
    "# G_loss = open('out/acc_loss/generator_loss.txt','w+')\n",
    "for epoch in range(80):\n",
    "    for i in range(total_batch):\n",
    "        #batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "        #batch_xp, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "        #batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "        #batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "        bstart, bend = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "        batch_xr, batch_xp = xr_train[bstart:bend], xp_train[bstart:bend]\n",
    "        batch_y = yr_train[bstart:bend]\n",
    "\n",
    "        # train discriminator\n",
    "        _, D_loss_curr = sess.run([D_optimizer, total_loss], feed_dict={xr: batch_xr, y: batch_y})\n",
    "        _, G_loss_curr = sess.run([G_optimizer, loss_p_d],   feed_dict={xr: batch_xr, y: batch_y})\n",
    "        if i % 2000 == 0:\n",
    "            print('D_loss: {:.4}'.format(D_loss_curr))\n",
    "            print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "#     D_loss.write(str(D_loss_curr)+'\\n')\n",
    "#     G_loss.write(str(G_loss_curr)+'\\n')\n",
    "# D_loss.close()\n",
    "# G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input accuracy 0.0006\n",
      "processed input accuracy 0.9796\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(output_fake, axis=-1), tf.argmax(y, axis=-1))\n",
    "accuracy_fake = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(output_real, axis=-1),tf.argmax(y, axis=-1))\n",
    "accuracy_real = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "\n",
    "print(\"raw input accuracy %g\"       %accuracy_real.eval(session=sess, feed_dict={xr: xr_test, y: yr_test}))\n",
    "print(\"processed input accuracy %g\" %accuracy_fake.eval(session=sess, feed_dict={xr: xr_test, \n",
    "                                                                                 xp: xp_test, y: yr_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./savemodel/cnn/cnn_generator.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess,\"./savemodel/cnn/cnn_generator.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## targeted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as session:\n",
    "# #print(mnist_raw.train.images[0])\n",
    "#   target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "#   out = session.run(target_class)\n",
    "#   print(out)\n",
    "##  out[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:33: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n",
      "/home/ldd/anaconda3/envs/py35/lib/python3.5/site-packages/cleverhans/compat.py:130: UserWarning: Running on tensorflow version 1.4.0. Support for this version in CleverHans is deprecated and may be removed on or after 2019-01-26\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000\n",
      "Iteration 4000\n",
      "Iteration 6000\n",
      "Iteration 8000\n",
      "Iteration 10000\n",
      "Iteration 12000\n",
      "Iteration 14000\n",
      "Iteration 16000\n",
      "Iteration 18000\n",
      "Iteration 20000\n",
      "Iteration 22000\n",
      "Iteration 24000\n",
      "Iteration 26000\n",
      "Iteration 28000\n",
      "Iteration 30000\n",
      "Iteration 32000\n",
      "Iteration 34000\n",
      "Iteration 36000\n",
      "Iteration 38000\n",
      "Iteration 40000\n",
      "Iteration 42000\n",
      "Iteration 44000\n",
      "Iteration 46000\n",
      "Iteration 48000\n",
      "Iteration 50000\n",
      "Iteration 52000\n",
      "Iteration 54000\n",
      "Iteration 56000\n",
      "Iteration 58000\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "attack_model = CNN('cnn', 10)\n",
    "NUM_CLASSES = 10\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "fgsm_params = {\n",
    "    'eps': 0.05,\n",
    "    'clip_min': 0,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': target_class\n",
    "}\n",
    "it = 10 # iterative FGSM\n",
    "\n",
    "fgsm = FastGradientMethod(attack_model, sess=sess)\n",
    "x_adv = fgsm.generate(x, **fgsm_params)\n",
    "adv_images = np.zeros((60000,28,28,1))\n",
    "for j in range(60000): # np.shape(xr_train)[0]=60000\n",
    "    adv_images[j] =xr_train[j].reshape(-1,28,28,1)\n",
    "    if j%2000==0:\n",
    "        print(\"Iteration \"+str(j))\n",
    "    for i in range(it):\n",
    "        adv_images[j] = sess.run(x_adv, feed_dict={x: adv_images[j].reshape(-1,28,28,1)}) #xr_train[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9874\n"
     ]
    }
   ],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "# _y = tf.placeholder(tf.float32, [None, 10])\n",
    "_, _output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "_correct_prediction = tf.equal(tf.argmax(_output_adv, -1), tf.argmax(target_class, -1))\n",
    "_accuracy = tf.reduce_mean(tf.cast(_correct_prediction, \"float\"))\n",
    "print(\"test accuracy %g\" %_accuracy.eval(session=sess, feed_dict={adv:adv_images}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd15991ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv_images[0].reshape(-1,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a surragte ATM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train for generator method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_generator(inputs, reuse=False):\n",
    "    with tf.variable_scope(\"surrogate_generator\", reuse=reuse) as scope:\n",
    "        x = conv2d(inputs, 32,5,5,1,1, name='conv1')\n",
    "        x = conv2d(x, 16,1,1,1,1, name='bottleconv')\n",
    "        x = conv2d(x, 16,3,3,1,1, name='conv2')\n",
    "        x = conv2d(x, 32,1,1,1,1, name='conv3')\n",
    "        x = slim.flatten(x, scope='flatten')\n",
    "        xl = slim.fully_connected(x, 784, activation_fn=None, scope='fc')\n",
    "        xl = tf.reshape(xl,[-1,28,28,1])\n",
    "        # xl = linear(x, 1, scope='fc')\n",
    "        xl = inputs + xl\n",
    "        xp = tf.nn.tanh(xl)\n",
    "        x_logits = slim.fully_connected(slim.dropout(x, 0.5), 10, activation_fn=None, scope='fc2')\n",
    "        x_logits = tf.nn.softmax(x_logits, name=\"softmax\")\n",
    "        # xl = tf.reshape(xl,[-1,28,28,1])\n",
    "        return x_logits, xp\n",
    "\n",
    "# define model\n",
    "_xr  = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "_adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "_y   = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "gen_adv_logits, gen_adv = surrogate_generator(_xr)\n",
    "\n",
    "_loss_label = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=gen_adv_logits, labels=_y))\n",
    "_loss_image = tf.reduce_mean(tf.square(_adv - gen_adv))\n",
    "_total_loss = tf.add(_loss_label, _loss_image)\n",
    "\n",
    "# learning rate\n",
    "_global_step = tf.Variable(0, trainable=False)   \n",
    "_lr_decayed = tf.train.exponential_decay(0.001, _global_step, 2*10000, 0.1, staircase=False)\n",
    "\n",
    "# variable list\n",
    "_all_var = tf.global_variables()\n",
    "_g_vars = [var for var in _all_var if 'generator' in var.name]\n",
    "# optimizer\n",
    "_G_optimizer = tf.train.AdamOptimizer(learning_rate=_lr_decayed).minimize(_total_loss, var_list=[_g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3329895 2.3025854 0.030404052\n",
      "1.475502 1.461248 0.014253981\n",
      "1.4750289 1.4612296 0.013799302\n",
      "1.4747822 1.461222 0.013560172\n",
      "1.474661 1.461237 0.013424051\n",
      "1.4745609 1.4612417 0.013319191\n",
      "1.4744755 1.4612529 0.01322258\n",
      "1.474326 1.4612579 0.01306803\n",
      "1.4741406 1.4613132 0.012827399\n",
      "1.4739842 1.4613082 0.0126759475\n",
      "1.4738555 1.4612632 0.012592285\n",
      "1.4737694 1.4612262 0.012543165\n",
      "1.4737015 1.4611994 0.012502133\n",
      "1.4736534 1.4611888 0.01246469\n",
      "1.4735955 1.4611919 0.012403612\n",
      "1.4735352 1.461183 0.01235221\n",
      "1.4734943 1.4611794 0.012314856\n",
      "1.4734555 1.4611795 0.012276007\n",
      "1.4734311 1.4611814 0.012249715\n",
      "1.4734 1.4611762 0.012223844\n",
      "1.4733443 1.4611769 0.012167422\n",
      "1.473302 1.4611684 0.0121335955\n",
      "1.4732358 1.4611645 0.012071388\n",
      "1.4732035 1.4611691 0.012034468\n",
      "1.4731762 1.4611702 0.012006097\n",
      "1.4731542 1.4611692 0.011984937\n",
      "1.4731095 1.4611634 0.011946066\n",
      "1.4730344 1.4611633 0.0118710585\n",
      "1.4730036 1.4611585 0.011845068\n",
      "1.472887 1.4611566 0.01173042\n",
      "1.4728701 1.4611568 0.0117133055\n",
      "1.4728011 1.4611557 0.011645449\n",
      "1.4727383 1.4611564 0.011581877\n",
      "1.4726757 1.4611557 0.011520071\n",
      "1.4726573 1.4611549 0.01150241\n",
      "1.4726372 1.4611529 0.01148428\n",
      "1.4726307 1.4611518 0.011478853\n",
      "1.4726033 1.461154 0.011449293\n",
      "1.4725971 1.4611517 0.011445359\n",
      "1.4726129 1.4611511 0.011461754\n",
      "1.4725636 1.4611516 0.011412001\n",
      "1.4724721 1.4611516 0.011320523\n",
      "1.472494 1.4611514 0.011342644\n",
      "1.4724488 1.4611509 0.011297981\n",
      "1.4724948 1.4611516 0.01134321\n",
      "1.4724467 1.4611508 0.011295856\n",
      "1.4724568 1.4611508 0.011306067\n",
      "1.4724969 1.4611506 0.011346181\n",
      "1.4725131 1.4611508 0.011362334\n",
      "1.4725088 1.4611504 0.011358327\n",
      "1.4725474 1.4611504 0.011397055\n",
      "1.472587 1.4611505 0.011436469\n",
      "1.4726068 1.4611505 0.011456207\n",
      "1.4726121 1.4611504 0.011461711\n",
      "1.4725499 1.4611503 0.011399642\n",
      "1.4725696 1.4611502 0.011419357\n",
      "1.4726143 1.4611502 0.01146415\n",
      "1.472601 1.4611502 0.011450926\n",
      "1.4726728 1.4611502 0.011522702\n",
      "1.4726803 1.4611502 0.011530185\n",
      "1.4726216 1.4611502 0.011471383\n",
      "1.4726046 1.4611502 0.011454507\n",
      "1.4725301 1.4611502 0.011379949\n",
      "1.4725239 1.4611502 0.011373805\n",
      "1.4724805 1.4611502 0.01133041\n",
      "1.4724628 1.4611502 0.011312607\n",
      "1.4724392 1.4611502 0.011288958\n",
      "1.4725161 1.4611502 0.011365832\n",
      "1.4725075 1.4611502 0.01135727\n",
      "1.4724278 1.4611502 0.011277659\n",
      "1.4723216 1.4611502 0.011171454\n",
      "1.4723063 1.4611502 0.011156069\n",
      "1.4722774 1.4611502 0.011127277\n",
      "1.47224 1.4611502 0.011089833\n",
      "1.4723618 1.4611502 0.011211653\n",
      "1.4722924 1.4611502 0.011142301\n",
      "1.472351 1.4611502 0.011200844\n",
      "1.4723423 1.4611502 0.011192142\n",
      "1.4723405 1.4611502 0.011190347\n",
      "1.4723419 1.4611502 0.011191669\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.tables_initializer())\n",
    "\n",
    "target_label = sess.run(target_class)\n",
    "\n",
    "# BATCH_SIZE = 128\n",
    "_total_batch = int(60000 / BATCH_SIZE)\n",
    "# T_loss = open('out/acc_loss/fixed_total_loss.txt','w+')\n",
    "# D_loss = open('out/acc_loss/fixed_r_loss.txt','w+')\n",
    "# G_loss = open('out/acc_loss/fixed_p_loss.txt','w+')\n",
    "for epoch in range(80):\n",
    "    for i in range(_total_batch):\n",
    "        bstart, bend = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "        batch_xr, batch_xp = xr_train[bstart:bend], adv_images[bstart:bend]\n",
    "        batch_y = np.repeat(target_label, BATCH_SIZE, axis=0)\n",
    "\n",
    "        _, G_loss_curr, _loss_l, _loss_i = sess.run([_G_optimizer, _total_loss, _loss_label, _loss_image],\n",
    "                                  feed_dict={_xr: batch_xr,\n",
    "                                             _adv: batch_xp,\n",
    "                                             _y: batch_y})\n",
    "        if i % 1000 == 0:\n",
    "            print(G_loss_curr, _loss_l, _loss_i)\n",
    "#     T_loss.write(str(t_loss)+'\\n')\n",
    "#     D_loss.write(str(temp_loss1)+'\\n')\n",
    "#     G_loss.write(str(temp_loss2)+'\\n')\n",
    "# T_loss.close()\n",
    "# D_loss.close()\n",
    "# G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator adversarial accuracy 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_xin = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xin\")\n",
    "# _y  = tf.placeholder(tf.float32, [None, 10])\n",
    "# target_label = sess.run(target_class)\n",
    "\n",
    "_gen_adv_logits, _gen_adv = surrogate_generator(_xin, reuse=True)\n",
    "\n",
    "g_sample = sess.run(_gen_adv, feed_dict={_xin: xr_test[0].reshape(-1,28,28,1)})\n",
    "plt.imshow(g_sample.reshape(-1,28))\n",
    "\n",
    "# calculate accuracy\n",
    "_correct_prediction = tf.equal(tf.argmax(_gen_adv_logits, axis=-1), tf.argmax(target_class, axis=-1))\n",
    "_accuracy_fake = tf.reduce_mean(tf.cast(_correct_prediction, \"float\"))\n",
    "\n",
    "print(\"generator adversarial accuracy %g\" %_accuracy_fake.eval(session=sess, feed_dict={_xin: xr_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data as tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    target_label = session.run(target_class)\n",
    "    \n",
    "filename = \"./out/adv_generator_mnist.tfrecords\"\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "for i in range(50000):\n",
    "    images_raw = adv_images[i].tostring()\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'label': _int64_feature(np.argmax(target_label)),\n",
    "        'image': _bytes_feature(images_raw)}))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# for i in range(50000):\n",
    "#     im = adv_images[i].reshape(28,28)\n",
    "#     img= Image.fromarray(im*255)\n",
    "#     img = img.convert('RGB')\n",
    "#     img.save('out/adversarial/generator/3/adv_%s.png'%i,'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type             Data/Info\n",
      "-----------------------------------------------\n",
      "BATCH_SIZE           int              128\n",
      "CIFAR10              type             <class 'cleverhans.dataset.CIFAR10'>\n",
      "CNN                  type             <class 'model.CNN'>\n",
      "CarliniWagnerL2      type             <class 'cleverhans.attacks.CarliniWagnerL2'>\n",
      "D_loss               TextIOWrapper    <_io.TextIOWrapper name='<...>de='w+' encoding='UTF-8'>\n",
      "D_loss_curr          float32          0.007557234\n",
      "D_optimizer          Operation        name: \"Adam\"\\nop: \"NoOp\"\\<...>input: \"^Adam/Assign_1\"\\n\n",
      "FastGradientMethod   type             <class 'cleverhans.attacks.FastGradientMethod'>\n",
      "G_loss               TextIOWrapper    <_io.TextIOWrapper name='<...>de='w+' encoding='UTF-8'>\n",
      "G_loss_curr          float32          0.007562696\n",
      "G_optimizer          Operation        name: \"Adam_1\"\\nop: \"NoOp<...>put: \"^Adam_1/Assign_1\"\\n\n",
      "G_sample             Tensor           Tensor(\"generator/Tanh:0\"<...>8, 28, 1), dtype=float32)\n",
      "MNIST                type             <class 'cleverhans.dataset.MNIST'>\n",
      "MyModel              type             <class 'model.MyModel'>\n",
      "all_var              list             n=15\n",
      "alpha                float            1.0\n",
      "batch_xp             ndarray          128x28x28x1: 100352 elems, type `float32`, 401408 bytes (392.0 kb)\n",
      "batch_xr             ndarray          128x28x28x1: 100352 elems, type `float32`, 401408 bytes (392.0 kb)\n",
      "batch_y              ndarray          128x10: 1280 elems, type `float32`, 5120 bytes\n",
      "bend                 int              59904\n",
      "beta                 float            1.0\n",
      "bstart               int              59776\n",
      "cv2                  module           <module 'cv2.cv2' from '/<...>35m-x86_64-linux-gnu.so'>\n",
      "d_vars               list             n=6\n",
      "dataset              str              mnist\n",
      "epoch                int              79\n",
      "fashion_mnist        module           <module 'keras.datasets.f<...>tasets/fashion_mnist.py'>\n",
      "g_vars               list             n=8\n",
      "gama                 float            0.01\n",
      "generator            function         <function generator at 0x7f450e4cee18>\n",
      "global_step          Variable         <tf.Variable 'Variable:0'<...>shape=() dtype=int32_ref>\n",
      "i                    int              467\n",
      "loss_d               Tensor           Tensor(\"mul_3:0\", shape=(), dtype=float32)\n",
      "loss_p               Tensor           Tensor(\"mul_2:0\", shape=(), dtype=float32)\n",
      "loss_p_d             Tensor           Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "loss_r               Tensor           Tensor(\"mul_1:0\", shape=(), dtype=float32)\n",
      "lr_decayed           Tensor           Tensor(\"ExponentialDecay:<...> shape=(), dtype=float32)\n",
      "mnist                MNIST            <cleverhans.dataset.MNIST<...>object at 0x7f4507bbe358>\n",
      "model                MyModel          <model.MyModel object at 0x7f4578527a58>\n",
      "network              str              cnn\n",
      "np                   module           <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "os                   module           <module 'os' from '/home/<...>y35/lib/python3.5/os.py'>\n",
      "output_fake          Tensor           Tensor(\"discriminator_1/s<...>e=(?, 10), dtype=float32)\n",
      "output_logits_fake   Tensor           Tensor(\"discriminator_1/f<...>e=(?, 10), dtype=float32)\n",
      "output_logits_real   Tensor           Tensor(\"discriminator/fc2<...>e=(?, 10), dtype=float32)\n",
      "output_real          Tensor           Tensor(\"discriminator/sof<...>e=(?, 10), dtype=float32)\n",
      "sess                 Session          <tensorflow.python.client<...>object at 0x7f450e655be0>\n",
      "test_end             int              10000\n",
      "test_start           int              0\n",
      "tf                   module           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "total_batch          int              468\n",
      "total_loss           Tensor           Tensor(\"add_1:0\", shape=(), dtype=float32)\n",
      "train_end            int              60000\n",
      "train_start          int              0\n",
      "xp                   Tensor           Tensor(\"xp:0\", shape=(?, <...>8, 28, 1), dtype=float32)\n",
      "xp_test              ndarray          10000x28x28x1: 7840000 elems, type `float32`, 31360000 bytes (29.9072265625 Mb)\n",
      "xp_train             ndarray          60000x28x28x1: 47040000 elems, type `float32`, 188160000 bytes (179.443359375 Mb)\n",
      "xr                   Tensor           Tensor(\"xr:0\", shape=(?, <...>8, 28, 1), dtype=float32)\n",
      "xr_test              ndarray          10000x28x28x1: 7840000 elems, type `float32`, 31360000 bytes (29.9072265625 Mb)\n",
      "xr_train             ndarray          60000x28x28x1: 47040000 elems, type `float32`, 188160000 bytes (179.443359375 Mb)\n",
      "y                    Tensor           Tensor(\"Placeholder:0\", s<...>e=(?, 10), dtype=float32)\n",
      "yr_test              ndarray          10000x10: 100000 elems, type `float32`, 400000 bytes (390.625 kb)\n",
      "yr_train             ndarray          60000x10: 600000 elems, type `float32`, 2400000 bytes (2.288818359375 Mb)\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
