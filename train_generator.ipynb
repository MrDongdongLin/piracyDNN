{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MyModel, CNN\n",
    "from cleverhans.attacks import FastGradientMethod, CarliniWagnerL2\n",
    "from cleverhans.dataset import MNIST, CIFAR10\n",
    "import perturbation as pb\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "(fr_train_images, fr_train_labels), \\\n",
    "(fr_test_images, fr_test_labels) = fashion_mnist.load_data()\n",
    "mnist_raw = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\" # mnist fashion\n",
    "network = \"cnn\"     # cnn resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"mnist\":\n",
    "  X_raw_train = mnist_raw.train.images\n",
    "  Y_raw_train = mnist_raw.train.labels\n",
    "  X_raw_test  = mnist_raw.test.images\n",
    "  Y_raw_test  = mnist_raw.test.labels\n",
    "elif dataset == \"fashion\":\n",
    "  frx_train = fr_train_images.reshape(fr_train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  fry_test  = fr_test_images.reshape(fr_test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_raw_train  = frx_train/255\n",
    "  Y_raw_train  = np_utils.to_categorical(fr_train_labels)\n",
    "  X_raw_test   = fry_test/255\n",
    "  Y_raw_test   = np_utils.to_categorical(fr_test_labels)\n",
    "  num_examples = fr_train_images.shape[0]\n",
    "  pattern      = np.reshape(pattern, (28, 28, 1))\n",
    "  fpx_train    = np.zeros(X_raw_train.shape)\n",
    "  fpx_test     = np.zeros(X_raw_test.shape)\n",
    "\n",
    "  for i in range(0, fr_train_images.shape[0]):\n",
    "    fpx_train[i] = X_raw_train[i] + pattern\n",
    "  for i in range(0, fr_test_images.shape[0]):\n",
    "    fpx_test[i] = X_raw_test[i] + pattern\n",
    "  X_process_train = fpx_train\n",
    "  Y_process_train = Y_raw_train\n",
    "  X_process_test  = fpx_test\n",
    "  Y_process_test  = Y_raw_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "X_r = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xr\")\n",
    "Y_r = tf.placeholder(tf.float32, [None, 10])\n",
    "# X_p = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"xp\")\n",
    "Y_p = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(10)\n",
    "# generate perturbation according to the input\n",
    "_, G_sample = pb.generator(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if network == \"cnn\":\n",
    "  output_logits_real, output_real = model.basic_cnn(X_r)\n",
    "  output_logits_fake, output_fake = model.basic_cnn(G_sample,reuse=True)\n",
    "elif network == \"resnet\":\n",
    "  output_logits_real, output_real = model.resnet20(X_r)\n",
    "  output_logits_fake, output_fake = model.resnet20(G_sample,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "gama = 10.\n",
    "loss_r = alpha * tf.reduce_mean(tf.reduce_sum(Y_r * output_real, -1))\n",
    "loss_p = beta * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_logits_fake, labels=Y_p))\n",
    "loss_d = gama * tf.reduce_mean(tf.square(X_r - G_sample))\n",
    "loss_p_d =  tf.add(loss_p, loss_d)\n",
    "total_loss = loss_r+loss_p+loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "global_step = tf.Variable(0, trainable=False)   \n",
    "lr_decayed = tf.train.exponential_decay(0.001, global_step, 2*10000, 0.1, staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-71f8942828ea>:2: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "# variable list\n",
    "all_var = tf.all_variables()\n",
    "g_vars = [var for var in all_var if 'generator' in var.name]\n",
    "d_vars = [var for var in all_var if 'discriminator' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(total_loss, var_list=[d_vars])\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr_decayed).minimize(loss_p_d, var_list=[g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 2.456\n",
      "G_loss: 2.354\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.2216\n",
      "G_loss: 0.08094\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.1637\n",
      "G_loss: 0.05523\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.1306\n",
      "G_loss: 0.03609\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.1039\n",
      "G_loss: 0.0553\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.1408\n",
      "G_loss: 0.04196\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.1061\n",
      "G_loss: 0.0309\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.1027\n",
      "G_loss: 0.02517\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.08982\n",
      "G_loss: 0.02778\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.09554\n",
      "G_loss: 0.02517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "i = 0\n",
    "D_loss = open('out/acc_loss/discriminator_loss.txt','a+')\n",
    "G_loss = open('out/acc_loss/generator_loss.txt','a+')\n",
    "for it in range(20000):\n",
    "#   if it % 2000 == 0:\n",
    "#     samples = sess.run(G_sample, feed_dict={X_r: X_raw_train[it].reshape(-1,28,28,1)})\n",
    "#     samples = (samples / 2 + 0.5)*255\n",
    "#     fig = plot(samples)\n",
    "#     plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#     cv2.imwrite('out/cv2_{}.png'.format(str(i).zfill(3)), samples.reshape(28,28,1))\n",
    "#     i += 1\n",
    "#     plt.close(fig)\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  _, D_loss_curr = sess.run([D_optimizer, total_loss],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  _, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "\n",
    "  if it % 2000 == 0:\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('D loss: {:.4}'.format(D_loss_curr))\n",
    "    print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "    print()\n",
    "  D_loss.write(str(D_loss_curr)+'\\n')\n",
    "  G_loss.write(str(G_loss_curr)+'\\n')\n",
    "\n",
    "D_loss.close()\n",
    "G_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of real data: 0.100\n",
      "accuracy of fake data: 0.999\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(output_fake, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_fake = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(output_real, axis=-1), \\\n",
    "        tf.argmax(Y_p, axis=-1))\n",
    "accuracy_real = tf.reduce_mean(tf.cast(correct_prediction1, \"float\"))\n",
    "# test processed input\n",
    "Accuracy_real = np.array([])\n",
    "Accuracy_fake = np.array([])\n",
    "for i in range(1000):\n",
    "    #batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    #batch_xp, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    #batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "    #batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  if dataset == \"mnist\":\n",
    "    batch_xr, batch_yr = mnist_raw.train.next_batch(batch_size)\n",
    "    # _, batch_yp = mnist_process.train.next_batch(batch_size)\n",
    "    batch_yp = batch_yr.copy()\n",
    "  elif dataset == \"fashion\":\n",
    "    batch_xr = X_raw_train[i*128:(i+1)*128]\n",
    "    batch_yr = Y_raw_train[i*128:(i+1)*128]\n",
    "    # batch_xp = X_process_train[i*128:(i+1)*128]\n",
    "    batch_yp = batch_yr.copy()\n",
    "    \n",
    "  batch_xr = batch_xr.reshape(-1, 28, 28, 1)\n",
    "  # batch_xp = batch_xp.reshape(-1, 28, 28, 1)\n",
    "\n",
    "  # train discriminator\n",
    "  temp_acc, temp_acc_ = sess.run([accuracy_real,accuracy_fake],\n",
    "                            feed_dict={X_r: batch_xr,\n",
    "                                       Y_r: batch_yr,\n",
    "                                       Y_p: batch_yp})\n",
    "  #_, G_loss_curr = sess.run([G_optimizer, loss_p_d], feed_dict={X_r: batch_xr, Y_p: batch_yp})\n",
    "  Accuracy_real = np.insert(Accuracy_real,0, temp_acc)\n",
    "  Accuracy_fake = np.insert(Accuracy_fake,0, temp_acc_)\n",
    "print('accuracy of real data: %.3f' % np.mean(Accuracy_real))\n",
    "print('accuracy of fake data: %.3f' % np.mean(Accuracy_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NUM_CLASSES = 10\n",
    "def step_fgsm(x, eps, logits):\n",
    "  label = tf.argmax(logits,1)\n",
    "  one_hot_label = tf.one_hot(label, NUM_CLASSES)\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_label,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x + eps*tf.sign(tf.gradients(cross_entropy,x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv,-1.0,1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    " \n",
    "def step_targeted_attack(x, eps, one_hot_target_class, logits):\n",
    "  #one_hot_target_class = tf.one_hot(target, NUM_CLASSES)\n",
    "  #print(one_hot_target_class,\"\\n\\n\")\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                  logits,\n",
    "                                                  label_smoothing=0.1,\n",
    "                                                  weights=1.0)\n",
    "  x_adv = x - eps * tf.sign(tf.gradients(cross_entropy, x)[0])\n",
    "  x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "  return tf.stop_gradient(x_adv)\n",
    "\n",
    "def step_ll_adversarial_images(x, eps, logits):\n",
    "  least_likely_class = tf.argmin(logits, 1)\n",
    "  one_hot_ll_class = tf.one_hot(least_likely_class, NUM_CLASSES)\n",
    "  one_hot_ll_class = tf.reshape(one_hot_ll_class,[1,NUM_CLASSES])\n",
    "  # This reuses the method described above\n",
    "  return step_targeted_attack(x, eps, one_hot_ll_class, logits)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b82ac07c0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoftmax_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'discriminator/fc2/add:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xr:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madv_image_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_targeted_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "softmax_tensor = sess.graph.get_tensor_by_name('discriminator/fc2/add:0')\n",
    "image_tensor = sess.graph.get_tensor_by_name('xr:0')\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "\n",
    "adv_image_tensor = step_targeted_attack(image_tensor, 0.05, target_class, softmax_tensor)\n",
    "# adv_image = mnist_raw.train.images[0].reshape(-1,28,28,1)\n",
    "# t = adv_image.copy()\n",
    "# adv_noise = np.zeros(t.shape)\n",
    "adv_image = np.zeros((50000,28,28,1))\n",
    "for j in range(50000):\n",
    "  adv_image = mnist_raw.train.images[j].reshape(-1,28,28,1)\n",
    "  if j%2000==0:\n",
    "    print(\"Iteration \"+str(j))\n",
    "  for i in range(10):\n",
    "    #print(\"Iteration \"+str(i))\n",
    "    adv_image[j] = sess.run(adv_image_tensor,{'xr:0': adv_images[j].reshape(-1,28,28,1)})\n",
    "#   adv_noise = np.concatenate((adv_noise, adv_image))\n",
    "#plt.imshow(adv_image.reshape(-1,28))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## targeted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as session:\n",
    "# #print(mnist_raw.train.images[0])\n",
    "#   target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "#   out = session.run(target_class)\n",
    "#   print(out)\n",
    "##  out[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 2000\n",
      "Iteration 4000\n",
      "Iteration 6000\n",
      "Iteration 8000\n",
      "Iteration 10000\n",
      "Iteration 12000\n",
      "Iteration 14000\n",
      "Iteration 16000\n",
      "Iteration 18000\n",
      "Iteration 20000\n",
      "Iteration 22000\n",
      "Iteration 24000\n",
      "Iteration 26000\n",
      "Iteration 28000\n",
      "Iteration 30000\n",
      "Iteration 32000\n",
      "Iteration 34000\n",
      "Iteration 36000\n",
      "Iteration 38000\n",
      "Iteration 40000\n",
      "Iteration 42000\n",
      "Iteration 44000\n",
      "Iteration 46000\n",
      "Iteration 48000\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "attack_model = CNN('cnn', 10)\n",
    "NUM_CLASSES = 10\n",
    "target_class = tf.reshape(tf.one_hot(2,NUM_CLASSES),[1,NUM_CLASSES])\n",
    "fgsm_params = {\n",
    "    'eps': 0.05,\n",
    "    'clip_min': 0,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': target_class\n",
    "}\n",
    "it = 10 # iterative FGSM\n",
    "\n",
    "fgsm = FastGradientMethod(attack_model, sess=sess)\n",
    "x_adv = fgsm.generate(x, **fgsm_params)\n",
    "adv_images = np.zeros((50000,28,28,1))\n",
    "for j in range(50000): # np.shape(xr_train)[0]=60000\n",
    "    adv_images[j] = mnist_raw.train.images[j].reshape(-1,28,28,1)\n",
    "    if j%2000==0:\n",
    "        print(\"Iteration \"+str(j))\n",
    "    for i in range(it):\n",
    "        adv_images[j] = sess.run(x_adv, feed_dict={x: adv_images[j].reshape(-1,28,28,1)}) #xr_train[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52d808b7b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(adv_images[8].reshape(-1,28), cmap='gray')\n",
    "#print(mnist_raw.train.labels[3])\n",
    "#plt.show()\n",
    "#save_image(t,(-1,28,28,1),\"original.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.99904\n"
     ]
    }
   ],
   "source": [
    "adv = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"adv\")\n",
    "output_logits_adv, output_adv = model.basic_cnn(adv, reuse=True)\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(output_adv, -1), \\\n",
    "        tf.argmax(target_class, -1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, \"float\"))\n",
    "print(\"test accuracy %g\" %accuracy2.eval(session = sess,\n",
    "      feed_dict = {\n",
    "          adv:adv_images}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(50000):\n",
    " im = adv_images[i].reshape(28,28)\n",
    " img= Image.fromarray(im*255)\n",
    " img = img.convert('RGB')\n",
    " img.save('out/adversarial/generator/3/adv_%s.png'%i,'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
